<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.4.523">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>On Uncertainty - 5&nbsp; Supervaluations</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./chap-06.html" rel="next">
<link href="./chap-04.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-text-highlighting-styles">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-dark.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-bootstrap" data-mode="light">
<link href="site_libs/bootstrap/bootstrap-dark.min.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-bootstrap" data-mode="dark">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<script type="application/json" class="js-hypothesis-config">
{
  "theme": "clean"
}
</script>
<script async="" src="https://hypothes.is/embed.js"></script>
<script>
  window.document.addEventListener("DOMContentLoaded", function (_event) {
    document.body.classList.add('hypothesis-enabled');
  });
</script>
<link rel="stylesheet" href="https://use.typekit.net/uzz2drx.css">


</head>

<body class="nav-sidebar floating nav-fixed slimcontent">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="./index.html">
    <span class="navbar-title">Brian Weatherson</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-papers" role="button" data-bs-toggle="dropdown" aria-expanded="false">
 <span class="menu-text">Papers</span>
    </a>
    <ul class="dropdown-menu dropdown-menu-end" aria-labelledby="nav-menu-papers">    
        <li>
    <a class="dropdown-item" href="https://brian.weatherson.org/quarto/papers.html">
 <span class="dropdown-text">All Papers</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="https://brian.weatherson.org/quarto/epist.html">
 <span class="dropdown-text">Epistemology</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="https://brian.weatherson.org/quarto/gdt.html">
 <span class="dropdown-text">Games and Decisions</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="https://brian.weatherson.org/quarto/books.html">
 <span class="dropdown-text">On Books</span></a>
  </li>  
    </ul>
  </li>
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-books" role="button" data-bs-toggle="dropdown" aria-expanded="false">
 <span class="menu-text">Books</span>
    </a>
    <ul class="dropdown-menu dropdown-menu-end" aria-labelledby="nav-menu-books">    
        <li>
    <a class="dropdown-item" href="https://brian.weatherson.org/ne/">
 <span class="dropdown-text">Normative Externalism</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="https://lda.weatherson.org/">
 <span class="dropdown-text">A History of Philosophy Journals</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="https://brian.weatherson.org/kahis/">
 <span class="dropdown-text">Knowledge: A Human Interest Story</span></a>
  </li>  
    </ul>
  </li>
  <li class="nav-item">
    <a class="nav-link" href="https://brian.weatherson.org/quarto/cv.html"> 
<span class="menu-text">CV</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="https://brian.weatherson.org/quarto/teaching.html"> 
<span class="menu-text">Teaching Notes</span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
          <div class="quarto-navbar-tools tools-wide">
    <a href="https://github.com/bweatherson/kahis-quarto" title="Source Code" class="quarto-navigation-tool px-1" aria-label="Source Code"><i class="bi bi-github"></i></a>
    <div class="dropdown">
      <a href="" title="Download" id="quarto-navigation-tool-dropdown-0" class="quarto-navigation-tool dropdown-toggle px-1" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download"><i class="bi bi-download"></i></a>
      <ul class="dropdown-menu dropdown-menu-end" aria-labelledby="quarto-navigation-tool-dropdown-0">
          <li>
            <a class="dropdown-item quarto-navbar-tools-item" href="./On-Uncertainty.pdf">
              <i class="bi bi-bi-file-pdf pe-1"></i>
            Download PDF
            </a>
          </li>
          <li>
            <a class="dropdown-item quarto-navbar-tools-item" href="./On-Uncertainty.epub">
              <i class="bi bi-bi-journal pe-1"></i>
            Download ePub
            </a>
          </li>
          <li>
            <a class="dropdown-item quarto-navbar-tools-item" href="./On-Uncertainty.docx">
              <i class="bi bi-bi-file-word pe-1"></i>
            Download Docx
            </a>
          </li>
      </ul>
    </div>
  <a href="" class="quarto-color-scheme-toggle quarto-navigation-tool  px-1" onclick="window.quartoToggleColorScheme(); return false;" title="Toggle dark mode"><i class="bi"></i></a>
</div>
      </div> <!-- /container-fluid -->
    </nav>
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./chap-05.html"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Supervaluations</span></a></li></ol></nav>
        <a class="flex-grow-1" role="button" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Synopsis</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./original.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Declaration of Originality</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./acknowledgments.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Acknowledgments</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chap-01.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">What Probability Isn’t</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chap-02.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">What Degrees of Belief Aren’t</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chap-03.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">What Degrees of Belief Are</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chap-04.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">What Probability Is</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chap-05.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Supervaluations</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chap-06.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Objections</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chap-07.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Philosophical Predecessors</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chap-08.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Constructivist Probability</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chap-09.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Vague Decision Theory</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chap-10.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Keynes and Probability</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chap-11.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">The Economic Consequences of Uncertainty</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./references.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">References</span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar"><div class="quarto-margin-header"><div class="margin-header-item">
<p>&nbsp;</p>
</div></div>
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">In this chapter:</h2>
   
  <ul>
  <li><a href="#introduction-1" id="toc-introduction-1" class="nav-link active" data-scroll-target="#introduction-1"><span class="header-section-number">5.1</span> 5.1 Introduction</a></li>
  <li><a href="#supervaluations" id="toc-supervaluations" class="nav-link" data-scroll-target="#supervaluations"><span class="header-section-number">5.2</span> 5.2 Supervaluations</a></li>
  <li><a href="#probability-sentences" id="toc-probability-sentences" class="nav-link" data-scroll-target="#probability-sentences"><span class="header-section-number">5.3</span> 5.3 Probability Sentences</a></li>
  <li><a href="#scope-and-the-t-schema" id="toc-scope-and-the-t-schema" class="nav-link" data-scroll-target="#scope-and-the-t-schema"><span class="header-section-number">5.4</span> 5.4 Scope and the T-schema</a></li>
  <li><a href="#validity" id="toc-validity" class="nav-link" data-scroll-target="#validity"><span class="header-section-number">5.5</span> 5.5 Validity</a></li>
  <li><a href="#models-and-conceptual-truths" id="toc-models-and-conceptual-truths" class="nav-link" data-scroll-target="#models-and-conceptual-truths"><span class="header-section-number">5.6</span> 5.6 Models and Conceptual Truths</a></li>
  <li><a href="#local-and-general-supervaluationism" id="toc-local-and-general-supervaluationism" class="nav-link" data-scroll-target="#local-and-general-supervaluationism"><span class="header-section-number">5.7</span> 5.7 Local and General Supervaluationism</a></li>
  <li><a href="#the-reasonableness-of-imprecision" id="toc-the-reasonableness-of-imprecision" class="nav-link" data-scroll-target="#the-reasonableness-of-imprecision"><span class="header-section-number">5.8</span> 5.8 The Reasonableness of Imprecision</a>
  <ul class="collapse">
  <li><a href="#ignorance" id="toc-ignorance" class="nav-link" data-scroll-target="#ignorance"><span class="header-section-number">5.8.1</span> 5.8.1 Ignorance</a></li>
  <li><a href="#rational-disagreement" id="toc-rational-disagreement" class="nav-link" data-scroll-target="#rational-disagreement"><span class="header-section-number">5.8.2</span> 5.8.2 Rational Disagreement</a></li>
  <li><a href="#vagueness" id="toc-vagueness" class="nav-link" data-scroll-target="#vagueness"><span class="header-section-number">5.8.3</span> 5.8.3 Vagueness</a></li>
  </ul></li>
  <li><a href="#the-reasonableness-of-precision" id="toc-the-reasonableness-of-precision" class="nav-link" data-scroll-target="#the-reasonableness-of-precision"><span class="header-section-number">5.9</span> 5.9 The Reasonableness of Precision</a></li>
  </ul>
<div class="toc-actions"><ul><li><a href="https://github.com/bweatherson/kahis-quarto/issues/new" class="toc-action"><i class="bi bi-github"></i>Report an issue</a></li></ul></div></nav>
    </div>
<!-- main -->
<main class="content page-columns page-full" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title"><span id="sec-chap-5" class="quarto-section-identifier"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Supervaluations</span></span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<section id="introduction-1" class="level2" data-number="5.1">
<h2 data-number="5.1" class="anchored" data-anchor-id="introduction-1"><span class="header-section-number">5.1</span> 5.1 Introduction</h2>
<p>When we say the probability of <em>p</em> is <em>x</em>, we mean, roughly, the reasonable degree of belief in <em>p</em> is <em>x</em>. If we could guarantee that for any evidence there was a unique degree to which it was reasonable to believe <em>p</em>, that would be the end of the story. This is the path that Carnap followed, but as I showed in earlier chapters there are several reasons to think it will not lead to a happy ending. Ordinary credences can be vague or imprecise, and there often seems to be different credences which are reasonable on a given body of evidence.</p>
<p>So I have to be more careful when stating the relationship between probability and reasonable degree of belief. The idea defended in this dissertation is that when there are many credences which are reasonable, probability sentences are vague. And the best approach for interpreting vague sentences is the technique of supervaluations. The vagueness in probability sentences mirrors the permissible imprecision in reasonable degrees of belief.</p>
<p>In this chapter I’ll defend the use of supervaluational semantics for probability sentences against a number of recent attacks. The only change I make to the orthodoxy here is that I claim that on a supervaluational account, sentences containing vague terms have scope ambiguities. Orthodox accounts confuse conventional resolutions of this vagueness with the literal or semantic content of sentences. Even if my general defence against these attacks fails, there are grounds for thinking the supervaluational approach is more plausible when it is applied here than when it is applied generally to vagueness.</p>
<p>In section 2 I’ll set out an orthodox supervaluational account. The orthodoxy may be (slightly) wrong, but it is clearly the best way to explain the mechanics of a supervaluational account. In section 3 I’ll show how this applies to probability sentences. Williamson objects to supervaluational accounts because, <em>inter alia</em>, they don’t respect Tarski’s T‑schema. I think this is a sound criticism of the orthodoxy; and in section 4 I introduce an amendment to overcome it. This amendment allows for sentences which would ordinarily be supervaluated – e.g.&nbsp;sentences containing vague terms, sentences containing definite descriptions – to have a scope ambiguity. Section 5 discusses the notion of validity in the context of sentences without truth values. Sections 6 and 7 respond to other recent objections to supervaluational accounts. Sections 8 and 9 discuss the notion of reasonable degrees of belief that I have used in the earlier sections. Section 8 fleshes out the arguments discussed in <a href="chap-03.html" class="quarto-xref"><span>Chapter&nbsp;3</span></a> for there being more than one reasonable probability function. And in section 9 I argue that it is reasonable (though not epistemically mandatory) to have precise degrees of belief in all propositions.</p>
</section>
<section id="supervaluations" class="level2 page-columns page-full" data-number="5.2">
<h2 data-number="5.2" class="anchored" data-anchor-id="supervaluations"><span class="header-section-number">5.2</span> 5.2 Supervaluations</h2>
<p>The simplest introduction to supervaluational semantics is through its account of vague predicates. Assume Jack is such that it’s unclear whether he is tall (for an adult male)<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a> or not. Jack, for example, might be somewhat taller than the average adult male, but not a lot taller. Neither ‘Jack is tall’ nor ‘Jack is not tall’ would seem like appropriate things to say. We might just say it’s vague whether or not Jack is tall.</p>
<div class="no-row-height column-margin column-container"><li id="fn1"><p><sup>1</sup>&nbsp;Whether or not someone is tall of course depends on the context. Someone can easily be tall for a jockey and not tall for a basketballer. We’ll assume context is invariant in what follows.</p></li></div><p>Many people have believed we should say that ‘Jack is tall’ lacks a truth value. The supervaluationist has a principled reason for saying this, as well as a full story about how ‘Jack is tall’ behaves in logical compounds. The core of the story is the set of possible precisifications of <em>tall</em>. More generally a precisification will make all of language precise, but we’ll leave that aside for now. A precisification <em>V</em> of tall assigns truth values (we’re assuming here that <em>true</em> and <em>false</em> are the only truth values) to every sentence of the form ‘<em>x</em> is tall’ in accordance with three constraints.</p>
<p>First, all (first-order)<a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a> truths of English must be preserved in the precisification. So if Al really is tall, then on every precisification ‘Al is tall’ must come out true. Similarly, if Bill really is not tall then on every precisification ‘Bill is tall’ must come out false. Secondly, some conceptual truths must be preserved. These are what Kit Fine (1975) calls penumbral connections. If Jack is taller than John, there can’t be a precisification according to which ‘Jack is tall’ comes out false, and ‘John is tall’ comes out true. Even if both Jack and John are borderline cases of tallness, so there are precisifications on which ‘Jack is tall’ comes out false and precisifications according to which ‘John is tall’ comes out true, there can’t be a precisification on which both occur, because no tall person is shorter than a not tall person. Thirdly, truth values of compounds in the precisification are given by the usual rules. So ‘Jack is not tall’ comes out true iff ‘Jack is tall’ comes out false; ‘Jack is tall and John is true’ comes out true iff ‘Jack is tall’ comes out true and ‘John is tall’ comes out true, and so on for the other connectives.</p>
<div class="no-row-height column-margin column-container"><li id="fn2"><p><sup>2</sup>&nbsp;I am using ‘first-order’ in the sense developed by Tarksi. So ‘Snow is white’ is a first-order sentence, ‘“Snow is white” is true’ is a second-order sentence, and so on. Section 6 will discuss the need for this restriction.</p></li></div><p>There will be uncountably many precisifications, but they will have some things in common. As we noted ‘Al is tall’ will come out true on all of them if Al really is tall. ‘Jack is tall and Jack is not tall’ will come out false on all precisifications, even if the conjunct which is false differs for different precisifications. If Jack is taller than John, ‘John is tall and Jack is not tall’ will also come out false on all precisifications, with again the possibility that different conjuncts come out false on different precisifications. The supervaluationist defines truth (in English) to be truth on all precisifications, and falsity (in English) to be falsehood on all precisifications. These will be referred to as supertruth and superfalsity.</p>
<p>It is worth pausing to note some of the effects of this method of evaluating compounds. There can be conjunctions which are false despite having no false conjuncts. Conversely, there can be disjuncts which are true despite having no true disjuncts. This will be the case when for every precisification, one or other disjunct is true, but there is no disjunct true on all precisifications. To take the classic example, ‘Jack is tall or not tall’ comes out true even though neither ‘Jack is tall’ nor ‘Jack is not tall’ come out true.</p>
<p>A similar effect arises for existentially quantified sentences. There can be predicates <em>F</em>, <em>G</em> such that ‘Some <em>F</em> is a <em>G</em>’ is true even though there is no <em>F</em>, say <em>a</em>, such that ‘<em>Fa</em>&nbsp;and&nbsp;<em>Ga</em>’ is true. This will occur when on every precisification some <em>F</em> or other is <em>G</em>, but there is no <em>F</em> which is a <em>G</em> according to all precisifications. Conversely, ‘All <em>F</em> are <em>G</em>’ can be false even if there is no <em>a</em> such that ‘<em>Fa</em> and <em>Ga</em>’ is false. These general points will be important in what follows, but as I’ll show in section 4 there is need for great care in how they are interpreted.</p>
</section>
<section id="probability-sentences" class="level2 page-columns page-full" data-number="5.3">
<h2 data-number="5.3" class="anchored" data-anchor-id="probability-sentences"><span class="header-section-number">5.3</span> 5.3 Probability Sentences</h2>
<p>As discussed in <a href="chap-04.html" class="quarto-xref"><span>Chapter&nbsp;4</span></a>, some probability functions are reasonable and some are not. There are still some matters to discuss concerning the distinction, but I’ll assume for now we have it. Each of these functions plays the same role in my theory that precisifications play in supervaluational accounts of vagueness. The truth value of a sentence according to each function can be easily worked out. A sentence like ‘The probability of <em>p</em> given <em>q</em> is greater than 1/2’ is true according to a probability function <em>Pr</em> iff <em>Pr</em>(<em>p</em>&nbsp;|&nbsp;<em>q</em>) &gt; 1/2. Probability sentences are true <em>simpliciter</em> iff they are true on all precisifications, false iff they are false on all precisifications.</p>
<p>This approach has much pragmatically to recommend it. First, all the theorems of the classical probability calculus turn out to be true. So, for example, it is true that ‘For all <em>p</em>, <em>q</em> there is an <em>x</em> ∈&nbsp;[0,&nbsp;1] such that the probability of <em>p</em> given <em>q</em> is <em>x</em>’. Given the great amount of work that has been put in over the years into developing the probability calculus, it would be unfortunate to have to give it all up, or to say that it is inapplicable to actual uses of ‘probability’. The objections to unwarranted precision in earlier chapters do not show that we should be rid of such theories; rather they show we should be rid of careless interpretations of them.</p>
<p>In particular it is not the case that there need be an <em>x</em> which makes ‘The probability of <em>p</em> given <em>q</em> is <em>x</em>’ true. If we’d ordinarily say the probability of <em>p</em> given <em>q</em> is vague, say vague over the interval [0.4, 0.55], then for some <em>x</em> the sentence ‘The probability of <em>p</em> given <em>q</em> is <em>x</em>’ will be neither true nor false (i.e.&nbsp;for those <em>x</em> in [0.4, 0.55]) and for all other values of <em>x</em> it will be false. However, the existentially quantified sentence will be true because on all precisifications (all reasonable probability functions), the probability of <em>p</em> given <em>q</em> takes a precise value.</p>
<p>Some might view this preservation as a negative: it isn’t just an interpretation of some of the theorems of the probability calculus they wanted to throw out. There are, however, other indisputable advantages. Say the probability of <em>p</em> (I’ll omit references to evidence except where necessary) is vague over a large interval, and the probability of <em>r</em> given <em>p</em> is some high value, say 0.9. Hence, the intervals over which the probability of <em>p</em> and the probability of <em>p</em>&nbsp;&amp;&nbsp;<em>r</em> are vague overlap. So, for example, the probability of <em>p</em> might be vague over [0.4, 0.55], and the probability of <em>p</em>&nbsp;&amp;&nbsp;<em>r</em> might be vague over [0.36, 0.495]. The probability of <em>p</em> is clearly greater than that of <em>p</em>&nbsp;&amp;&nbsp;<em>r</em>. On a supervaluationist account this is true, since according to every reasonable probability function we have <em>Pr</em>(<em>p</em>) &gt; <em>Pr</em>(<em>p</em>&nbsp;&amp;&nbsp;<em>r</em>). On a purely ‘intervalist’ account I doubt this can be shown, for reasons given in 3.5.3.</p>
<p>So we have three reasons for adopting the supervaluational semantics suggested here for probability sentences. First, it allows us to keep the theorems of the classical probability calculus. Secondly, it explains why we might have thought some of these theorems were inappropriate by showing that some natural interpretations of these theorems are false. Thirdly, it gives the intuitively appropriate truth value to comparatives, something that other semantics which allow vagueness cannot do. These benefits are distinct from the general benefits of adopting supervaluational semantics for definite descriptions or vague terms, such as the natural account it provides of compounds.</p>
<p>There is one other complication which can be resolved by a supervaluational approach. I have said in the above that all probability sentences make a reference, either explicit or implicit, to an evidence set. When this is implicit there might be some vagueness as to what the evidence is. I think the best solution here is again a supervaluational approach. So a probability sentence is true iff it is true on all possible resolutions of this vagueness, false iff it is false on all possible resolutions of this vagueness, and lacking a truth value otherwise.</p>
<p>When talking about the probability of a proposition about the future this is not normally a problem, as usually this is a reference to chance. So, if I say that the probability of Al Gore winning the 2000 election is <em>x</em>, I mean the chance of him winning is <em>x</em>, where chance is defined as in the previous chapter. However, for propositions about the past this cannot generally be right, because the chance of the proposition being true will be zero or one. So if I say ‘The probability the suspect is guilty is at least 1/2’ it mightn’t be clear whether the implicit evidence set is all the evidence in the public domain, all the evidence I have, all the evidence that I share with my hearer, or some other set. Context will usually narrow the range a little, but it can’t be guaranteed to do all the work. In these cases what I say might be true on some resolutions of the vagueness and false on others, hence lacking a truth value.</p>
<p>For these reasons I agree to some extent with the claim in Price (1984) that probability sentences can fail to be truth-apt (which I interpret as lacking a truth value) because the reference to evidence may not be precise. He says that probability sentences will be truth-apt when there is agreement as to what the evidence is<a href="#fn3" class="footnote-ref" id="fnref3" role="doc-noteref"><sup>3</sup></a>, but when there is no such agreement there can be disputes where speakers say opposing things without either necessarily being mistaken, so their claims are not truth‑apt. The position adopted here is that when the different implicit evidence sets speakers use are close enough without being exactly the same, there can be genuine disputes, and hence truth-apt claims. For example, I can have a debate with someone about whether Oswald probably killed JFK even if we disagree a bit about what counts as evidence, so we can at least presuppose that our utterances are truth-apt. What counts as ‘close enough’ in the above definition will depend crucially on what is being talked about; for uncontroversial claims it will be defined widely and, conversely, for borderline claims it might be defined narrowly.</p>
<div class="no-row-height column-margin column-container"><li id="fn3"><p><sup>3</sup>&nbsp;I disagree with this in general, because of the possibility of imprecision, but since that isn’t what’s at issue just here, I’ll assume all probabilities are precise. I also presume that agreement as to what the evidence is need only be with an imaginary interlocutor, so that a probability sentence will be truth-apt if we could specify what the evidence is, even if this doesn’t happen in the actual conversation. Should this not be the case then the truth value of speakers’ utterances will depend implausibly on subsequent utterances of actual interlocutors.</p></li></div><p>One advantage of this position is that we do naturally assign truth values to some probability sentences even when the implicit evidence is a bit imprecisely defined. For example, if I say ‘There is probably no present king of France’, even if it is massively unclear from context what is to count as evidence, the utterance seems to be true. On the other hand for more disputable claims, such as in the debate about Kennedy’s assassin, imprecision in the definition of evidence may destroy the truth-aptness of the claims. All these results sound intuitively plausible, at least to my ear.</p>
</section>
<section id="scope-and-the-t-schema" class="level2 page-columns page-full" data-number="5.4">
<h2 data-number="5.4" class="anchored" data-anchor-id="scope-and-the-t-schema"><span class="header-section-number">5.4</span> 5.4 Scope and the T-schema</h2>
<p>Timothy Williamson (1994) claims adopting that supervaluational semantics leads to a denial of Tarski’s T-schema. And if the T-schema isn’t all we know about truth, it is, claims Williamson, a large enough part that we shouldn’t give it up. The point of this section is to make two responses to Williamson, and to show that at least one of these allows a response to an objection which Mark Sainsbury believes refutes supervaluational approaches.</p>
<p>Say <em>F</em> is a vague predicate. On a supervaluational approach, the sentence ‘<em>Fa</em>&nbsp;∨&nbsp;¬<em>F</em>a’ will always be true, for on every precisification of <em>F</em> one or other disjunct is true. However, the sentence ‘“<em>Fa</em>” is true or “¬<em>Fa</em>” is true’, need not be true. In particular, if <em>a</em> is a borderline case of being an <em>F</em>, then on some precisifications <em>Fa</em> will be false on the precisification, so <em>Fa</em> is not supertrue. Further, there will be precisifications according to which <em>Fa</em> is true on the precisification, so ¬<em>Fa</em> is not supertrue. So we can have ‘<em>Fa</em>&nbsp;∨&nbsp;¬<em>F</em>a’ true without ‘“<em>Fa</em>” is true or “¬<em>Fa</em>” is true’ being true. This result is acknowledged by supervaluationists; indeed something like it is usually taken to be one of the distinctive claims supervaluationists make.</p>
<p>Now if this is right, Williamson notes, we can’t keep the T-schema. For that schema says that for any proposition <em>A</em>, the material biconditional ‘<em>A</em> iff “<em>A</em>” is true’ holds. Now, given this, and some fairly straightforward logical machinery<a href="#fn4" class="footnote-ref" id="fnref4" role="doc-noteref"><sup>4</sup></a>, we can deduce the material biconditional (1), where <em>A</em> and <em>B</em> are any propositions:</p>
<div class="no-row-height column-margin column-container"><li id="fn4"><p><sup>4</sup>&nbsp;To be precise, the standard natural deduction rules ∨-introduction, ∨-elimination and <em>modus ponens</em>.</p></li></div><p>(1) (<em>A</em>&nbsp;or&nbsp;<em>B</em>)&nbsp;iff (“<em>A</em>” is true or “<em>B</em>” is true).</p>
<p>Strictly, (1) isn’t an instance of the T-schema, but it is an implication of it. As noted above, if the T‑schema is taken to be incontrovertible, the supervaluationist has a difficulty. It is a difficulty Williamson thinks is inescapable without moving to an epistemic conception of vagueness, according to which there is only ever one permissible precisification, but we are ignorant as to what it is. I will make two responses; the first of which is very similar to one Williamson discusses and rejects, and the second of which is quite different.</p>
<p>The response which Williamson discusses is to claim that there is a disquotational truth predicate, <em>true<sub>T</sub></em>. This response was first raised in Fine (1975), though he develops it somewhat differently to the way I am doing. ‘“<em>A</em>” is true’ is true<sub>T</sub> according to a precisification iff <em>A</em> is true according to that precisification, where <em>iff</em> is read as the material biconditional. Williamson acknowledges this move rebuts his objection, but claims that once it is adopted there is no reason not to identify truth with truth<sub>T</sub> rather than with supertruth. For example, a plausible truth-functional account of validity can be given if this identification is made<a href="#fn5" class="footnote-ref" id="fnref5" role="doc-noteref"><sup>5</sup></a>. And if we do identify truth with truth<sub>T</sub> rather than with supertruth, Williamson claims we lose all that is distinctive about the supervaluationist position. We just fall back into his preferred position, that vagueness is an epistemic phenomenon. “Of supervaluationism, nothing remains articulate,” he concludes (1994: 164).</p>
<div class="no-row-height column-margin column-container"><li id="fn5"><p><sup>5</sup>&nbsp;Williamson notes that the supervaluationist might argue that identifying truth with truth<sub>T</sub> will mean that not every sentence will be definitely true or definitely not true, and we might have thought this a flaw in a semantic theory. However, he claims that given the existence of higher‑order vagueness, even identifying truth with supertruth will not preserve this condition. And here some card-carrying supervaluationists agree with him. See for example Williams (1976).</p>
<p>For what it’s worth, we can also give a plausible truth-functional account of validity if we identify truth with supertruth, but validity won’t just mean truth preservation; it must also mean never going from non-false premises to false conclusions. More on this in later sections.</p></li></div><p>A different way of running this response is to claim that there is no reason <em>supertrue</em> shouldn’t behave like <em>true<sub>T</sub></em>. The standard way of assessing sentences like ‘“<em>A</em>” is true or “<em>B</em>” is true’ is to evaluate each disjunct separately. But this goes against a central tenet of supervaluationist theory, which says that to determine the truth value of complex sentences containing vague terms we have to look at the truth value of the whole sentence according to each precisification. This rule, it seems, needs to be extended to sentences which contain vague terms <em>quoted</em>.</p>
<p>On this variant of supervaluationism, what ought we say about the truth of ‘“<em>A</em>” is true’ according to a precisification? According to that precisification, all terms in <em>A</em> are precise, and hence all have just one admissible precisification. Hence this sentence will be true (according to all precisifications) according to that precisification iff it is true according to that precisification. In a more digestible soundbite, supertruth according to a precisification equals truth according to that precisification. Hence (1) will be hold. In the troubling case, it might be impossible to identify the true disjunct on the right of the biconditional, but there will be one.</p>
<p>If this move is made, it becomes impossible to <em>say</em> what is distinctive about the supervaluationist approach. To see this, consider a case where we would normally say that <em>Some Fs are Gs</em> is supertrue while for any particular <em>F</em>, say <em>x</em>, <em>Gx</em> would not be supertrue, as different <em>F</em>s are <em>G</em> according to different precisifications. All of the following are literally false according to this approach.</p>
<p>(2) There is no <em>x</em> such that ‘<em>Fx</em> and <em>Gx</em>’ is supertrue.</p>
<p>(3) There is no correct answer to the question, ‘Which <em>F</em> is <em>G</em>?’.</p>
<p>(4) No <em>F</em> is such that it is a <em>G</em> according to all precisifications.</p>
<p>All of these have the common feature that they are true if we are speaking from outside the supervaluational framework; speaking about that framework without using it. But this cannot be done. So says the hard-line supervaluationist. The attempt to say things like (2) to (4) and hence capture what is distinctive about the supervaluational position is an attempt to find a linguistic ‘view from nowhere’. Williamson is right to say that nothing articulate and distinctive remains about this supervaluational position.</p>
<p>It isn’t clear, however, that there remains nothing distinctive at all about this approach. It can’t be said what it is, but perhaps this isn’t too surprising. We shouldn’t be too surprised to learn that there are things about a language that we can’t say in that language. That will hold whether the language is as precise as the formal language of <em>Principica Mathematica</em>, or as vague as ordinary English. We might hint at what is distinctive about the supervaluational position by saying things like (2) to (4), but if this variant of supervaluationism is correct, vague languages are rather incomplete in the sense that we cannot use them to say things we would like to be able to say. The idea is that by saying (2), (3) or (4) we are exploiting the circumlocutional nature of our utterances to implicate (i.e.&nbsp;point to) something which can’t be said<a href="#fn6" class="footnote-ref" id="fnref6" role="doc-noteref"><sup>6</sup></a>.</p>
<div class="no-row-height column-margin column-container"><li id="fn6"><p><sup>6</sup>&nbsp;Interpreted literally, there is a problem with this last paragraph. On every precisification there is nothing that can’t be said, so the sentence ‘There is something that can’t be said’ must come out false by virtue of being false on all precisifications. I take this to be another confirming instance of Ramsey’s rule: what can’t be said can’t be whistled.</p></li></div><p>I think this position has some attractions (theoretical simplicity for example) but I can’t imagine it will persuade anyone. There is a different way. It might be permissible to read (2) to (4) in a way in which they come out literally false, but there is also a reading under which they are true. All of these sentences have scope ambiguities, and different resolutions of these scope ambiguities will lead to differing truth values for the sentences. (2), for example, could be rendered as (2a) or (2b), the first false, the second true.</p>
<p>(2a) According to all precisifications, there is no <em>x</em> such that ‘<em>Fx</em> and <em>Gx</em>’ is true (according to all precisifications).</p>
<p>(2b) There is no <em>x</em> such that according to all precisifications ‘<em>Fx</em> and <em>Gx</em>’ is true (according to all precisifications).</p>
<p>Once it is seen that there is always going to be a reading like (2a), where the ‘internal’ reading<a href="#fn7" class="footnote-ref" id="fnref7" role="doc-noteref"><sup>7</sup></a> of the sentence is formed by prefixing ‘according to all precisifications’, we see that these scope ambiguities are ineliminable. So there is no point trying to eliminate them by adding more and more words. Rather we use a convention such that the quantification over precisifications is given wide scope in ‘simple’ sentences and narrow scope in ‘complex’ sentences. So according to the convention, (2) should be read as (2b)<a href="#fn8" class="footnote-ref" id="fnref8" role="doc-noteref"><sup>8</sup></a>.</p>
<div class="no-row-height column-margin column-container"><li id="fn7"><p><sup>7</sup>&nbsp;In contrast to the ‘view from nowhere’ reading.</p></li><li id="fn8"><p><sup>8</sup>&nbsp;This convention could be read as a conventional implicature. This would lead to the conclusion that the T‑schema was literally true, as the left and right sides have the same semantic content, but they have differing conventional content. In any case, it is uncontroversial that the different sides have different pragmatic properties.</p>
<p>There might be a question as to how such a convention could have come about. My best explanation would be that because the developers of supervaluational semantics said things like (2), (3) and (4) and intended them to be read truly, readers applied the principle of charity and read them as truths. When subsequent writers talking about supervaluational semantics use sentences like these, we are reminded of the classical usage, and hence interpret them the same way. Thus a convention develops, and it spreads again by usage of charity on textbook writings using similar sentences in a similar way. I make no claim for the empirical accuracy of this story: however, I do hope that some story like it can be told to explain the creation of the convention.</p></li></div><p>The scope ambiguity isn’t confined to sentences like (2). On the contrary, ‘Some <em>Fs</em> are <em>Gs</em>’ is capable of being read both like (2a) and like (2b). Here, though, the convention is that we read it like (2a). Now every instance of the T‑schema will hold as long as we disambiguate both sides in the same way. The argument purporting to show that, from premises the supervaluationist is committed to, an instance of the T‑schema is falsified rests, according to this analysis, on a fallacy of ambiguity.</p>
<p>Sainsbury (1988: 41) claims that supervaluationists are committed to denying the existence of vague terms. Consider the classic vague term <em>heap</em>. Every precisification of <em>heap</em> can be summarised by a single number <em>n</em>: piles of sand with <em>n</em> or more grains are heaps, and with less than <em>n</em> grains are not heaps. So Sainsbury notes according to supervaluationist accounts, (5) should be true.</p>
<p>(5) For some number <em>n</em>, an <em>n</em>-grained collection is a heap, but a (<em>n</em>&nbsp;‑&nbsp;1)‑grained collection is not.</p>
<p>This, he claims, is pretty much a denial of the vagueness of <em>heap</em>; vagueness means <em>inter alia</em>, having no sharp boundary. The scope ambiguity analysis allows the supervaluationist a reply. (5) is ambiguous between (5a) and (5b); (5a) is the reading which is literally true and (5b) is the reading which amounts to a denial of the vagueness of <em>heap</em>. But no reading is true and amounts to denial of the vagueness of <em>heap</em>.</p>
<p>(5a) According to all precisifications, for some number <em>n</em>, an <em>n</em>-grained collection is a heap, but a (<em>n</em>&nbsp;‑&nbsp;1)‑grained collection is not.</p>
<p>(5b) For some number <em>n</em>, according to all precisifications, an <em>n</em>-grained collection is a heap, but a (<em>n</em>&nbsp;‑&nbsp;1)‑grained collection is not.</p>
<p>So the supervaluationist has two replies to the arguments put by Sainsbury and Williamson. The first involves the rather startling claim that once we supervaluate many of the analyses of vague sentences, we find they are literally false. There are, on this reply, many things we would like to be able to say about sentences with vague terms, but our language doesn’t have the resources to say them. The second reply is that sentences containing existential quantifications or disjunctions involving vague terms have scope ambiguities. The conclusions to which Williamson and Sainsbury believe the supervaluationist is committed can only be drawn by failing to distinguish carefully enough the different readings of these sentences.</p>
<p>There is an important objection to this view which needs a rather careful argument to refute. I have held that disjunctive utterances containing vague terms are ambiguous between their two supervaluational readings, and this ambiguity is a scope ambiguity. There is no reason why my claim shouldn’t extend to ordinary utterances. So, assuming again that Jack is a borderline case of baldness, then (6) should be ambiguous between a reading on which it lacks a truth value and a reading on which it is false.</p>
<p>(6) Jack is bald.</p>
<p>Now there’s nothing too implausible about the first part of this conclusion. <em>Ex hypothesi</em>, Jack isn’t one of the bald things, so we should be able to say (6) is false. On the other hand, since Jack is a borderline case of baldness, many writers have thought it correct to deny (6) a truth value. So far, then, we don’t have a telling objection. What is a problem is that it looks implausible to say that the ambiguity in (6) is a scope ambiguity. A scope ambiguity requires that there is a quantifier which could be placed in various parts of the sentence; (6) doesn’t have the required multiple insertion points and, hence, is not susceptible to scope ambiguity. I could avoid this problem by postulating a brute ambiguity; but this is incredible and in any case would be inconsistent with the theoretical position I adopted in the last chapter. Apart from homonyms like ‘bank’, all ambiguity should be explainable in principle; and when a word behaves ambiguously in several contexts, the same explanation should be given for the range of behaviour displayed.</p>
<p>To show that the ambiguity in (6) really is a scope ambiguity we need to consider why a sentence lacks a truth value. To consider this we must first consider why the sentence might be true. As Dummett (1959) stressed, it is a mistake to consider truth in isolation from our practices of asserting and believing. We like to believe true sentences; generally we like to assert true sentences. We want to make arguments which preserve truth. Any purported account of truth, belief, assertion and arguing which does not take these things into account will be mistaken. If we cash out these desires as beliefs about what would happen in ideal conditions (truth is what we believe in ideal conditions) we are lead into constructivism, but there is no need to analyse them that way. Lewis (1988) has showed there are theoretical reasons for not analysing desires as beliefs of any kind. We can accept these points about truth without becoming anti-realists.</p>
<p>I have given some properties of truth; we have certain desires expressible in terms of it and it has a certain place in a theoretical network that includes belief, assertion and argument. Assume I can give enough properties to get an analysis of truth. So a sentence is true iff it has property <em>T</em>. The analysis is a little misleading; the sentence is <em>T</em> because it is true, not <em>vice versa</em>. It must now be decided what will count as an analysis of ‘false’. If I was committed to saying all sentences are true or false I could simply say that a sentence is false if it is not <em>T</em>. Given that I am trying to analyse what is meant by saying a sentence lacks a truth value, this looks like the wrong path to take.</p>
<p>Rather, I will say that a sentence is false iff its negation is <em>T</em>. This seems to capture the motivation of many theorists who deny some sentences truth values; they fear that saying a sentence is false commits them implausibly to the truth of some other sentence. Since that other sentence is not one they want to assert or believe, not one they would like to have as the conclusion of a good argument with true premises, they deny the original sentence is false.</p>
<p>This raises the rather obvious question, how do we tell what the negation of a sentence really is. In the case of (6) this is somewhat non-trivial. Many would argue that the negation of (6) should just be (7).</p>
<p>(6) Jack is bald.</p>
<p>(7) Jack is not bald.</p>
<p>Since (7) is not <em>T</em>, and it is the negation of (6), we conclude (6) is not false. The problem is that the second premise here looks dubious. If we accept a Russellian account of definite descriptions, we have to say that (9) is not the negation of (8).</p>
<p>(8) The present king of France is bald.</p>
<p>(9) The present king of France is not bald.</p>
<p>Famously, Russell said they were both false<a href="#fn9" class="footnote-ref" id="fnref9" role="doc-noteref"><sup>9</sup></a>. Yet they stand in the same syntactic relationship to each other as (6) and (7), so if negation is a syntactic relationship, (7) is not the negation of (6). I don’t take this little argument to show that (7) is not the negation of (6); I do take it to show that the relationship between (7) and (6) isn’t as clear as some have supposed<a href="#fn10" class="footnote-ref" id="fnref10" role="doc-noteref"><sup>10</sup></a>. The official definition of the negation of (6) in introductory logic texts is generally (10).</p>
<div class="no-row-height column-margin column-container"><li id="fn9"><p><sup>9</sup>&nbsp;At least on one reading of (9).</p></li><li id="fn10"><p><sup>10</sup>&nbsp;Including Russell himself. He said that in cases of vagueness, where we deny ‘Jack is bald’ and deny ‘Jack is not bald’, we are committed to denying a case of excluded middle (1923: 88).</p></li></div><p>(10) It is not the case that Jack is bald.</p>
<p>(11) ‘Jack is bald’ is not true.</p>
<p>I take it that it is unclear whether (10) should be interpreted as (7) or as (11). The good news from the view of the ambiguity theory being defended here is that (10) does seem to have a scope ambiguity, and the two readings correspond to (7) and (11).</p>
<p>(7a) According to all precisifications it is not the case that Jack is bald.</p>
<p>(11a) It is not the case that Jack is bald according to all precisifications.</p>
<p>This explains why (6) is ambiguous. The truth value of a sentence depends both on whether it is <em>T</em> and on whether its negation is <em>T</em>. Since (6) is not <em>T</em>, it cannot be true. But whether it is false or gappy depends on whether its negation is <em>T</em>. There is a scope ambiguity in its negation, so we can say that the truth value of (6) is ambiguous. Finally, whenever the truth value of a sentence is ambiguous, that sentence is ambiguous. Hence the ambiguity in (6) is not ‘brute’, it can be explained in terms of scope, so the objection fails.</p>
<p>This analysis of negation is not at all new; something like it appears to be going on in Russell (1905:&nbsp;53). He says that (9) is ambiguous; whether or not it is true depends on whether we regard the denoting expression as, in his terms, ‘primary’ or ‘secondary’. It is false if it says the present king of France is among the things which are not bald; this is the primary reading. It is true if it denies that among the bald things is the present king of France; this is the secondary reading. The main difference is that it is clear that the negation of (8) is the secondary reading of (9), whereas in this example it does look genuinely ambiguous what should be the negation of (6).</p>
<p>For ease of reference, I’ll call the first of the two responses listed here <em>strong supervaluationism</em>, and the second <em>moderate supervaluationism</em>. The traditional approach is then called <em>weak supervaluationism</em>. The names derive from how far the various theories say supervaluational approaches should be applied. Since the strong approach seems so unlikely to be persuasive, unless otherwise stated I’ll assume the moderate version is correct in what follows.</p>
</section>
<section id="validity" class="level2 page-columns page-full" data-number="5.5">
<h2 data-number="5.5" class="anchored" data-anchor-id="validity"><span class="header-section-number">5.5</span> 5.5 Validity</h2>
<p>Williamson’s other primary objection to the supervaluationist approach to the resolution of vagueness is that it lacks a plausible account of validity. Within the supervaluational literature there are two definitions of validity: local and global validity. Local validity says that an argument is valid iff it is traditionally valid on every precisification. In other words, if whenever all the premises are true on a precisification, the conclusion is also true. Global validity says that an argument is valid if whenever the premises are all true on all precisifications, the conclusion is also true on all precisifications. In other words, validity is supertruth preservation. Local validity is defended by Dummett (1975), global validity by Fine (1975).</p>
<p>Williamson claims that since the supervaluationist identifies truth with supertruth, they must plump for global validity as the appropriate account of validity. He then notes that this account of validity will not allow some intuitively plausible inference rules (in particular <em>reductio ad absurdum</em>) and concludes the supervaluationist has some implausible commitments.</p>
<p>I’ll concede that global validity is an implausible standard of validity. However, I don’t see why the supervaluationist should be committed to it. Sentences of the form ‘<em>p</em> entails <em>q</em>’ (or alternatively ‘Γ entails <em>q</em>’) have a scope ambiguity of the sort mentioned above. We can interpret (1) as either (1a) or (1b).</p>
<p>(1) <em>p</em> entails <em>q</em>.</p>
<p>(1a) According to all precisifications, <em>p</em> entails <em>q</em>.</p>
<p>(1b) <em>p</em> according to all precisifications entails <em>q</em> according to all precisifications.</p>
<p>Moderate supervaluationism says that (1a) is at least a legitimate reading of (1). Indeed, since it is the only reading licensed by strong supervaluationism, it is perhaps the primary reading. If we insist on reading (1) as (1b) then we may be lead to incoherence; but if we insist on supervaluating some sentences and not others this is perhaps not too surprising.</p>
<p>If we interpret (1) as (1a) we get Dummett’s local validity as the proper account of validity for supervaluationists. Since local validity preserves all the standard rules of entailment Williamson’s argument would collapse. We don’t, when using local validity, use our definition of truth as supertruth in our account of validity. Williamson suggests that this implies we are not really committed to this definition. Were we to read (1) as (1b) and still use local validity as the appropriate criteria Williamson would be correct here, but, as that’s not what we’re doing, I don’t see the objection here.</p>
<p>Even if we interpret (1) as (1b), global validity is still not the right theory of validity. Such an approach assumes that, in effect, we have three truth values<a href="#fn11" class="footnote-ref" id="fnref11" role="doc-noteref"><sup>11</sup></a>: &lt;true, gap, false&gt; and only the first of these is designated. Such an approach runs foul of an objection Dummett (1959) makes to Strawson’s account of definite descriptions. Strawson (1950) says that ‘The present king of France is bald’ lacks a truth value because it has a non-referring definite description. Dummett replies that Strawson hasn’t accurately distinguished lacking a truth value from being false. In particular, since ‘gap’ is in effect undesignated in Strawson’s system, it looks like Strawson has merely distinguished two types of falsehood rather than distinguished falsehoods from sentences lacking truth values.</p>
<div class="no-row-height column-margin column-container"><li id="fn11"><p><sup>11</sup>&nbsp;Strictly ‘gap’ is not a truth value, it is the lack of one, but spelling this out every time would make the exposition unreadable, so I presume the reader can remember this caveat.</p></li><li id="fn12"><p><sup>12</sup>&nbsp;Neither distinction I am using is redundant. The previous section showed how to determine whether particular sentences are gappy or false; this section provides a stronger argument for the claim that there is a real difference between these two ‘values’.</p></li></div><p>To motivate a theory which says that some sentences lack truth values, I have to do something which distinguishes ‘gap’ from ‘false’. I made some progress towards that in the previous section; false sentences have true negations, gappy sentences do not. I can now make a more direct distinction between the two<a href="#fn12" class="footnote-ref" id="fnref12" role="doc-noteref"><sup>12</sup></a>. ‘Gap’ is, in the best account of validity for three-valued logics, neither a designated nor an undesignated value, as the account of validity is not a designated value account. Rather, I say that an argument is valid iff it satisfies the following criteria.</p>
<p>‘<em>p</em> entails <em>q</em>’ is valid iff</p>
<p>(i) it is impossible for <em>p</em> to be true and <em>q</em> to be not-true; and</p>
<p>(ii) it is impossible for <em>p</em> to be not-false and <em>q</em> to be false.</p>
<p>It is easy to check this cannot be represented as a designated values account of validity. Such an account is quite popular in the literature<a href="#fn13" class="footnote-ref" id="fnref13" role="doc-noteref"><sup>13</sup></a>, and it’s clear why. Not only does it escape Dummett’s objection to Strawson, it preserves contraposition and <em>reductio</em>. ‘<em>p</em> entails <em>q</em>’ is valid iff ‘¬<em>q</em> entails ¬<em>p</em>’ is valid. And ‘<em>p</em> entails <em>q</em> and ¬<em>q</em>’ is valid, iff for any <em>r</em>, ‘<em>r</em> entails ¬<em>p</em>’ is valid. The motivation for this account is the scale of truth values &lt;true, gap, false&gt; mentioned above. An argument is valid iff it is impossible in moving from the premise to the conclusion to move ‘down’ the scale, either from true to anything else, or from gap to false.</p>
<div class="no-row-height column-margin column-container"><li id="fn13"><p><sup>13</sup>&nbsp;Most recently McDermott (1996); see the references therein for earlier proponents.</p></li></div><p>There are some complications in the story for when we have a set of premises or a set of conclusions. And this story will not preserve all the classical rules. For example conditional proof is no longer sound; nor is argument by cases, sometimes called ∨ elimination. However, the fact that even on my non-preferred reading of (1) I can keep <em>reductio</em> and contraposition suggests that there is no objection from this direction to the supervaluational approach.</p>
</section>
<section id="models-and-conceptual-truths" class="level2 page-columns page-full" data-number="5.6">
<h2 data-number="5.6" class="anchored" data-anchor-id="models-and-conceptual-truths"><span class="header-section-number">5.6</span> 5.6 Models and Conceptual Truths</h2>
<p>Fodor and Lepore (1996)<a href="#fn14" class="footnote-ref" id="fnref14" role="doc-noteref"><sup>14</sup></a> have recently claimed there is a simple objection to supervaluational semantics. They claim that the precisifications which are the core of this account do not satisfy a mandatory condition on models for a language: that all conceptual truths are true in the model. Because of this there is no reason to think ‘truth in all precisifications’ is really truth.</p>
<div class="no-row-height column-margin column-container"><li id="fn14"><p><sup>14</sup>&nbsp;All references in this section to this paper unless otherwise stated.</p></li></div><p>The objection is built up as follows. Vague terms like ‘bald’ have a penumbra. Assume for the sake of the argument that a person with 1/9 of their head covered with their own hair is in this penumbra, neither definitely bald nor definitely not bald. If the ratio is wrong, it can be changed. All that matters is that there is one, which everyone agrees. Let <em>S</em> be the sentence ‘A person with a head-to-hair ratio of 1/9 is bald’. If our assumption is right, <em>S</em> is neither definitely true nor definitely false. Indeed, on standard accounts <em>S</em> is neither true nor false <em>simpliciter</em>.</p>
<p>That <em>S</em> is not definitely true is not something that we discovered by looking at the world. Of course we discovered what <em>S</em> means by looking at the world, but once we found that out we worked out by conceptual analysis alone that it is not definitely true. So ‘<em>S</em> is not definitely true’ is a conceptual truth. Fodor and Lepore then wield what they call principle (P).</p>
<blockquote class="blockquote">
<p>“(P) Conceptual truths must be respected by all classical models, including classical valuations.” (521).</p>
</blockquote>
<p>The justification is that a purported model of a language which does not respect conceptual truths is not a genuine model. “If there are conceptual truths, then they determine what the topic under discussion <em>is</em>, so they must not be flouted on pain of equivocation.” (521). But precisifications do not satisfy this criteria. To see this, note that in many precisifications, ‘<em>S</em> is not definitely true’ comes out as false, despite being a conceptual truth. In all those precisifications in which it does come out as true, the conceptual truth ‘<em>S</em> is not definitely false’ comes out as false. So there are no precisifications which satisfy principle (P).</p>
<p>As well as this general argument for (P), they have an <em>ad hominen</em> against the supervaluationist who does not accept it. Say, Al and Bill each have 1/9 of their head covered with their own hair. Then there are, according to supervaluationism, acceptable precisifications according to which ‘Al is bald’ comes out true. There are also acceptable precisifications according to which ‘Bill is bald’ comes out false. But there is no acceptable precisification according to which ‘Al is bald’ comes out true and ‘Bill is bald’ comes out false. Referring to Fine (1975), Fodor and Lepore claim that the supervaluationists’ reason for this is that precisifications must preserve conceptual truths, in this case the conceptual truth that baldness supervenes on head-to-hair ratio. So by their own lights, supervaluationists are committed to (P). But there are no precisifications which are acceptable according to (P).</p>
<p>The response to Fodor and Lepore is three-fold. First, some reasons for thinking that (P) need not be satisfied by models are discussed. The basic point is that precisifications of English are not meant to be meaning preserving at the level they are discussing. It’s no news to say ‘bald’ in a precisification means something different from ‘bald’ in English because the former is precise and the latter is vague. The second is that we can distinguish acceptable from unacceptable precisifications without relying on (P). Finally, it is argued that there is no way to make sense of Fodor and Lepore’s positive suggestion, which is that <em>S</em> is gappy, and must be so on all models, without using supervaluations. In sum, I don’t dispute that giving up principles like (P) is part of the cost of adopting a supervaluational account, but I think the cost can be shown to be rather small, and the benefits rather large.</p>
<p>Fodor and Lepore treat precisifications as languages, so we can talk about the meaning of a word in a precisification. It is simpler to treat them as sets of true sentences, or equivalently as (complete) functions from sentences to truth-values. In any case, we ought to be able to determine the meaning of a word in a precisification from the set of sentences containing that word which are true. Let <em>E</em> be the set of first-order truths of English. So ‘Snow is white’ is in <em>E</em>, but ‘“Snow is white” is true’ is not in <em>E</em>. Let <em>E</em><sup>*</sup> be any maximally consistent superset of <em>E</em> which is closed in the following ways:</p>
<p><em>A</em>&nbsp;&amp;&nbsp;<em>B</em> ∈&nbsp;<em>E</em><sup>*</sup> iff <em>A</em>&nbsp;∈&nbsp;<em>E</em><sup>*</sup> and <em>B</em>&nbsp;∈&nbsp;<em>E</em><sup>*</sup></p>
<p><em>A</em>&nbsp;∨&nbsp;<em>B</em> ∈&nbsp;<em>E</em><sup>*</sup> iff <em>A</em>&nbsp;∈&nbsp;<em>E</em><sup>*</sup> or <em>B</em>&nbsp;∈&nbsp;<em>E</em><sup>*</sup></p>
<p>¬<em>A</em>&nbsp;∈&nbsp;<em>E</em><sup>*</sup> iff <em>A</em>&nbsp;∉&nbsp;<em>E</em><sup>*</sup></p>
<p>If <em>A</em>&nbsp;→ <em>B</em>&nbsp;∈&nbsp;<em>E</em><sup>*</sup> and <em>A</em>&nbsp;∈&nbsp;<em>E</em><sup>*</sup> then <em>B</em>&nbsp;∈&nbsp;<em>E</em><sup>*</sup></p>
<p>‘<em>A</em>’ is true ∈&nbsp;<em>E</em><sup>*</sup> iff <em>A</em>&nbsp;∈&nbsp;<em>E</em><sup>*</sup></p>
<p><em>E</em><sup>*</sup> is a precisification of English iff it satisfies all of these conditions. I’m intending ‘→’ here to be read as a natural language conditional; the condition regarding it is redundant if it is read as a material implication. This definition is intended to perform two jobs. First, any (first-order) truths of English are true in all precisifications. So if Jack is bald then ‘Jack is bald’ will be an element of all precisifications.</p>
<p>Secondly, precisifications preserve what Fine called the penumbral connections, like ‘Taking someone’s hair away doesn’t change them from being bald to not-bald’. The way these were preserved by Fine suggested that supervaluationists were committed to (P). However, here they are preserved not because they are conceptual truths, but because they are first-order. For example, ‘Baldness supervenes on hair-to-head ratio’ is a first-order truth, so it will be in <em>E</em><sup>*</sup>. Returning to our example of Al and Bill, this implies that ‘If Al is bald, Bill is bald’ is in <em>E</em> and hence <em>E</em><sup>*</sup>. I’m assuming here that if <em>A</em> entails <em>B</em> then ‘If <em>A</em>, <em>B</em>’ is true. Hence there can be no precisification in which Al is bald and Bill is not bald. Similarly, we can find general (perhaps conceptual) first-order truths which imply that bald people can’t have a higher hair-to-head ratio than non-bald people.</p>
<p>It’s a trivial fact that for one object to model another, it doesn’t have to have all the properties of the object being modelled, or indeed all the essential properties. Consider the use of crash test dummies to model the behaviour of humans in car crashes. So on a natural reading of ‘model’, there is no reason to say that precisifications are not models of English just because they lack essential properties of English. There are two ways in which breach of (P) by precisifications would cause problems, but neither seem to be realistic possibilities.</p>
<p>First, if someone were claiming ‘bald’ in <em>E</em><sup>*</sup> means the same as ‘bald’ in English, then breaches of (P) would be problematic. Meaning-preserving translations ought to preserve conceptual truths. But there is a bigger problem with this approach. It would imply that we can work out the meaning of ‘bald’ by just stipulating a cut-off point. Since any stipulation would provide the meaning, this would lead to blatant inconsistencies. This clearly isn’t what supervaluationists are trying to do. The meaning of ‘bald’ isn’t given by its behaviour in a particular precisification, but in the set of them.</p>
<p>Secondly, there might be a difficulty if there were permutation problems. Granted that <em>E</em><sup>*</sup> is a model (not an analysis or translation) of English, we have to determine which English words are being modelled by particular words in <em>E</em><sup>*</sup>. Ideally there will be a function from words in <em>E</em><sup>*</sup> to words in English. However, there might be multiple plausible functions. Were this to occur then <em>E</em><sup>*</sup> wouldn’t be a good model, and there might be wholesale difficulties for the supervaluationist, because it wouldn’t be clear if the equivalent sentence in the model to a particular sentence of English were true or not. However, there is little evidence that there are such problems, and hopefully the preservation of all first-order truths in all precisifications prevents such a difficulty occurring. If there is a problem on these lines, no objector has yet shown it.</p>
<p>From this we can determine that the status of ‘Jack is not definitely bald’ in a precisification will depend on how we read ‘definitely’. If we read it as a function from predicates to predicates (like ‘very’) we will assume that this is a first-order truth (if Jack is in the penumbra of bald), and so it will be true in all precisifications. On the other hand, if by this we mean ‘“Jack is bald” is not definitely true’, then it is a second order truth. This will be true in some models and not in others. I assume that what is true in a model is, for reasons given in previous sections, definitely true in that model. So this conceptual truth will not be preserved in all models, but we have reasons for thinking models need not preserve conceptual truths.</p>
<p>This answers the letter of Fodor and Lepore’s objections. Precisifications need not obey (P) because they are models of English, not analyses or translations of it. And we can capture Fine’s penumbral connections without relying on (P), so there is no <em>ad hominen</em> argument for (P). There remains, however, a powerful related problem. Why, given that precisifications are merely models for English, should truth on all models mean truth in English? For the first-order sentences, the answer is trivial. If a first-order sentence is true on all precisifications which preserve all first-order truths, then of course it is true. The question is why this should be the case for the higher-order sentences.</p>
<p>There is here no quick answer. The long answer turns on four points. First, given that this approach works for first-order sentences, there is an argument from theoretical simplicity to use it everywhere. This needs little elaboration, but it isn’t that powerful on its own. The second is that only supervaluational theories justify saying that some sentences lack a truth-value. The third is that, given that some sentences lack a truth-value, only the moderate supervaluational approach avoids implausible results. A fourth, which won’t be elaborated but which might have some power, is that the supervaluational explanation of the truth-value of compounds with gappy components is preferable to its rivals.</p>
<p>Many of these points have been stressed in previous sections, and there’s no need to recap them here. I have made much of the general argument against the existence of ‘gappy’ sentences in my replies to some objections of Williamson. We can’t just stipulate that sentences without truth values exist, we need to explain what we mean by this, and in particular we need to explain why we take being ‘gappy’ to be different from being ‘false’.</p>
<p>Even if this general hurdle is cleared, we need to explain why some vague sentences should be ‘gappy’. I have argued above that the easiest way to do this is to show that the negations of these sentences are not true. If it can be shown that ‘Jack is not bald’ should be considered the negation of ‘Jack is bald’, the task might be complete. The supervaluationist can show this easily; ‘Jack is not bald’ is undoubtedly the negation of ‘Jack is bald’ on all precisifications, so it is plausibly its negation <em>simpliciter</em>. For other theories, however, the arguments near the end of section 5.4 seem to show this can’t be done. So Fodor and Lepore’s preferred position, that sentences like ‘Jack is bald’ are gappy and that’s all there is to the matter, looks flawed.</p>
<p>Moderate supervaluationists can explain how there can be gappy sentences even though Tarski’s T‑schema is preserved. This is quite an achievement, as the T‑schema threatens the consistency of accounts which allow gappiness. Assume that neither <em>A</em> nor ¬<em>A</em> is true. Then by the T‑schema and <em>modus tollens</em>, both ¬<em>A</em> and ¬¬<em>A</em> are true, which is a contradiction. According to supervaluationists, this little argument contains a fallacy of equivocation. However, it isn’t clear how non-supervaluational accounts are to avoid it.</p>
<p>In general I suppose the move will be to render the T‑schema impotent, as van Fraassen (1966) does in his attempt to defend weak supervaluationism. He claims that we lose the T‑schema, but this is no great loss as both “<em>A</em>&nbsp; ‘<em>A</em>’ is true” and “‘<em>A</em>’ is true <em>A</em>” are still valid. However, his argument for saying these are valid relies on there being no higher-order vagueness, and on validity being mere truth-preservation, rather than the stronger rule outlined at the end of the last section. Each of these premises seems to be mistaken.</p>
<p>The argument for supervaluationism here relies, it might be thought, a little too heavily on the weaknesses of its rivals. In part that’s not accurate, some of the objections above are to all possible opposing accounts, not just those now on the market. However, in part it’s an unavoidable problem. The challenge Fodor and Lepore put forward can be easily met for one class of sentences (the first-order sentences), the difficulty is just expanding it beyond that. Since the main ground for expansion is theoretical simplicity and the coherence of a unified approach, much of the discussion is going to be concerned with counting the costs of going this way as compared to going another. Once that point is reached, negative arguments seem likely to be most prominent.</p>
<p>Fodor and Lepore do anticipate somewhat this general line of reply. In a long footnote, they note that some critics have suggested the conceptual truths they want precisifications to honour are metalinguistic, higher-level truths. They first suggest this oughtn’t matter. I take it this is the same as pressing the question of why, given our justification, we should apply supervaluational semantics to higher-order sentences. This objection I’ve already considered. They then claim the truths are not higher-level with the following argument.</p>
<blockquote class="blockquote">
<p>The crucial consideration is that you cannot make a man more (/less) bald without altering his hair-to-head ratio. So if there is any valuation on which [‘Al is bald’] is true (/false /indeterminate) and Al’s head-to-hair ratio is m&nbsp;/&nbsp;n, then [‘Al is bald’] is true (/false /indeterminate) in every valuation in which Al’s head-to-hair ratio is m&nbsp;/&nbsp;n.&nbsp;(523n)</p>
</blockquote>
<p>The question turns on whether (1) is true.</p>
<p>(1) If <em>A</em> is true on any precisification, it is true on all of them.</p>
<p>Surprisingly, there is an argument for (1), just the little argument from facts about supervenience that Fodor and Lepore give. I take it this can be generalised from sentences about baldness to sentences generally. The moderate supervaluationist respects this argument; on their view (1) is ambiguous. The standard reading would have it come out at least possibly false. However, there is a reading which we get by prefixing ‘According to all precisifications’ to (1), on which it is necessarily true. The simple fact which this reading expresses is that according to a precisification, it is the only acceptable precisification. However, trying to use that to show there can’t be more than one precisification, or that metalinguistic sentences aren’t of a different type to ordinary sentences, rests on a fallacy of ambiguity.</p>
</section>
<section id="local-and-general-supervaluationism" class="level2" data-number="5.7">
<h2 data-number="5.7" class="anchored" data-anchor-id="local-and-general-supervaluationism"><span class="header-section-number">5.7</span> 5.7 Local and General Supervaluationism</h2>
<p>I think a broad supervaluational program succeeds; supervaluational semantics are correct for at least sentences with vague predicates, and possibly also for ambiguous sentences. However, even if this program were to fail, I think a supervaluational program for probability sentences would still succeed, because the objections to supervaluationism seem particularly weak when applied here.</p>
<p>It is conceded that the precisifications that supervaluationists use when interpreting vague terms are fictions. All of these precisifications have some features which differ from English; they are all precise. On the other hand the precisifications we use for interpreting probability sentences are much more natural. Each of them does represent a reasonable epistemic state, even though, since all of them are precise, there are reasonable epistemic states which are not precisifications. So the differences which Fodor and Lepore stress between models of languages and those languages are not real differences here.</p>
<p>There is also a distinction in terms of theoretical priority. In a natural language the vague terms are theoretically prior; we introduce the precisifications as a theoretical device for understanding these terms. In this case we start at a more theoretical position. The only contribution of natural language is to draw the link between probability and reasonable credences. What counts as reasonable will itself be largely determined by theoretical reflection. As it happens, the theory I have used here (developed in <a href="chap-03.html" class="quarto-xref"><span>Chapter&nbsp;3</span></a>) takes the precise probability functions as the basic elements, and allows degrees of belief to be imprecise by allowing them to be vague over a set of these functions. In these cases, it isn’t too surprising that we should define truth in terms of what is true according to each of these reasonable functions.</p>
<p>To put this point differently: in understanding probability, as in understanding credences, I take comparative, qualitative sentences to be primary. A probability function is reasonable iff it makes all of the comparative sentences true. Given that the comparative sentences are primary, and the admissible probability functions make all of them true, it is no great stretch to say that true probability sentences are just those true according to all functions. If we didn’t have the theoretical arguments for the importance of probability functions (as opposed to just any old functions which made the comparative sentences true) this move would look quite unjustified; but with those arguments, it looks a little bland.</p>
<p>So in sum, even if the defences constructed above crack and supervaluational approaches are shown not to work for interpreting vague sentences, the specific usage of supervaluational semantics here may still be secure. I hope that doesn’t happen. I would like to see a general supervaluational program succeed, but I don’t think the fate of my theory of probability depends upon it.</p>
</section>
<section id="the-reasonableness-of-imprecision" class="level2 page-columns page-full" data-number="5.8">
<h2 data-number="5.8" class="anchored" data-anchor-id="the-reasonableness-of-imprecision"><span class="header-section-number">5.8</span> 5.8 The Reasonableness of Imprecision</h2>
<p>It is implicitly assumed above that there is more than one reasonable probability function. Some arguments for this were mentioned in <a href="chap-03.html" class="quarto-xref"><span>Chapter&nbsp;3</span></a>. This section will examine those arguments in more detail. There are three important classes of arguments for that conclusion: arguments from ignorance; arguments from rational disagreement and arguments from vagueness.</p>
<section id="ignorance" class="level3 page-columns page-full" data-number="5.8.1">
<h3 data-number="5.8.1" class="anchored" data-anchor-id="ignorance"><span class="header-section-number">5.8.1</span> 5.8.1 Ignorance</h3>
<p>There are some propositions about which we have next to no evidence. Classically the probability of these propositions was determined by Laplace’s principle of indifference. So, if we know, for example, nothing about a coin that’s about to be tossed, we ought assign equal credence to the proposition that it will fall heads if tossed as to the proposition that it will fall tails. In general, the principle says that we can infer from the absence of evidence about <em>p</em> and <em>q</em> that the probabilities of the two are equal.</p>
<p>In gaming situations this does not lead to implausible results, but when applied more widely it can do so. The classic examples of this are first presented in Bertrand (1889). This example is first due to von Kries (1886). A factory makes cubes of random sizes, the largest having a side length of 2cm, and the smallest having a side length of 0. What is the probability that the last cube to come off the production line had a side length greater than 1cm on just the evidence we have? By applying Laplace’s principle we seem to get the answer 1/2; the evidence that the cube’s side length is larger than 1cm is equal to the evidence that its side length is less than 1cm. However, we could instead look at the evidence about what the volume of the cube is. We know that the volume is at most 8cm<sup>3</sup>, and for every interval [<em>n</em>, <em>n</em>+1] (0&nbsp;≤ <em>n</em>&nbsp;≤ 7) the evidence that the volume is in that interval is identical. So the probability the volume is less than 1cm<sup>3</sup> is 1/8. But the volume is less than 1cm<sup>3</sup> iff the side length is less than 1cm. Hence the probabilities of the two should be the same. It seems that Laplace’s principle leads to inconsistency.</p>
<p>The importance of this is that, without Laplace’s principle, there is no way to represent ignorance about <em>p</em> through a single probability function<a href="#fn15" class="footnote-ref" id="fnref15" role="doc-noteref"><sup>15</sup></a>. Since ignorance is, it seems, possible, we should be able to represent it. And we should be able to say what epistemic states are reasonable under ignorance. If we allow multiple reasonable probability functions, this is possible, as has been shown. This argument has some historical importance, as it seems it is what convinced Keynes (1921a: ch.&nbsp;4) to allow degrees of belief to be incommensurable.</p>
<div class="no-row-height column-margin column-container"><li id="fn15"><p><sup>15</sup>&nbsp;This conclusion might be a bit quick; the constructivist theory developed in later chapters promises to do just this without Laplace’s principle. But it is clearly right for orthodox probability functions.</p></li></div><p>There are several related arguments to this one which are worth stating, but which have little independent force. In traditional epistemology, an agent is allowed to not have beliefs about a proposition. That is, we distinguish ‘<em>A</em> believes ¬<em>p</em>’ from ‘<em>A</em> doesn’t believe <em>p</em>’. In natural language words which would seem to indicate the latter often are used for the former, but this doesn’t mean the distinction isn’t real.</p>
<p>Many probabilistic epistemologies are not so liberal. So traditional subjectivism demands that an agent have a precise credence in a proposition, and that this be 1 less their credence in that proposition’s negation. In other words, it demands the agent have an epistemic attitude towards that proposition, a demand from which traditional epistemology recoils. The epistemology here is probabilistic but it allows reasonable agents to take no epistemic stance towards propositions. If an agent has no thoughts at all about a proposition <em>p</em>, then their epistemic state will be represented by a set of probability functions which includes a function <em>Pr</em> such that <em>Pr</em>(<em>p</em>)&nbsp;=&nbsp;<em>x</em> for all <em>x</em> in [0, 1]. An argument similar to this one is used in Jeffrey (1983) for allowing probabilities to be vague.</p>
</section>
<section id="rational-disagreement" class="level3 page-columns page-full" data-number="5.8.2">
<h3 data-number="5.8.2" class="anchored" data-anchor-id="rational-disagreement"><span class="header-section-number">5.8.2</span> 5.8.2 Rational Disagreement</h3>
<p>I take it as a datum that reasonable people can, on the same evidence, have different degrees of belief in the same proposition. That is, there is more than one reasonable response to certain bodies of evidence. I don’t, for example, regard it as evidence that one or other discussant is unreasonable, if participants in a debate about the Kennedy assassination express different credences in Oswald’s guilt. The evidence permits some doubt; how strongly that doubt is felt seems to vary among reasonable people.<a href="#fn16" class="footnote-ref" id="fnref16" role="doc-noteref"><sup>16</sup></a></p>
<div class="no-row-height column-margin column-container"><li id="fn16"><p><sup>16</sup>&nbsp;This is a little speculative, for ‘reasonable’ here entails ‘coherent’, and few people’s beliefs are fully coherent. So we can’t verify this claim by simply finding reasonable people with the same evidence who disagree. However, it seems implausible to think the kinds of disagreement mentioned in the text would dissipate were the disputants to obtain perfect computational powers.</p></li></div><p>In other words, I take it that the possibility for reasonable people to differ in the likelihood of a hypothesis given some evidence is something that a theory of probability should be required to explain. If there were only one reasonable probability function this explanation would be hard to find. However, on the theory adopted here it is easily explained because of the existence of multiple reasonable probability functions.</p>
<p>Some people may dispute the intuition on which this argument relies. If so I have no response; I hope the other arguments are more convincing. A more important objection to this argument is that it looks like an <em>ad hoc</em> move. The possibility of rational disagreement seems to threaten the whole project of analysing probability as reasonable degree of belief. It is incorporated only by weakening the semantics to allow for imprecise probability statement. If this argument were the only ground for allowing multiple reasonable probability functions, the objection would I think succeed. But that isn’t the argument I am using here. Like Keynes, I take the need to represent epistemic states with minimal evidence as the primary ground for allowing imprecision. That the most natural way to do so has this pleasant side‑effect, that it allows rational disagreement, should count as evidence we’re on the right track.</p>
</section>
<section id="vagueness" class="level3 page-columns page-full" data-number="5.8.3">
<h3 data-number="5.8.3" class="anchored" data-anchor-id="vagueness"><span class="header-section-number">5.8.3</span> 5.8.3 Vagueness</h3>
<p>There is a more direct argument for allowing imprecision. Try to determine, to the fifteenth decimal place, your credence that the Bulls will win the next N.B.A. title, or the Democrats the next Presidential election. It simply can’t be done; credences are not that precise. We have to have some way of representing vagueness, and the method used here seems better than the alternatives.</p>
<p>This argument is a bit quick. It might be responded that we do really have precise credences but they are subject to ordinary measurement errors. This is the response Borel (1924) makes to an imaginary objection like the one above. It might be, as Williamson (1994) suggests, that vagueness is in general an epistemic phenomenon; there is a sharp divide between the tall and the not‑tall but we are unaware of what it is. Similarly there might be precise credences we have in all propositions of which we are unaware.</p>
<p>Borel’s response would work if there were independent reasons for thinking credences are precise. We could then explain away the anomalous introspective evidence as a measurement problem. But I don’t see what those independent reasons could be, and without them the most natural interpretation of the evidence, that credences appear imprecise because they really are, seems most appropriate.</p>
<p>Whatever the general merits of Williamson’s resolution of the problem of vagueness that type of approach seems inappropriate here<a href="#fn17" class="footnote-ref" id="fnref17" role="doc-noteref"><sup>17</sup></a>. There is nothing implausible about insisting we can have (partial) beliefs of which we are unaware. So we might have a precise credence in the Bulls winning but be unaware of it. On a broadly functionalist view, provided we have all the right dispositions that go along with believing the Bulls will win to degree 0.4, we do believe that to degree 0.4, whatever the introspective evidence. It is, however, just as implausible that we have sufficient dispositions to settle our credence to the fifteenth decimal place as that we could determine that credence introspectively.</p>
<div class="no-row-height column-margin column-container"><li id="fn17"><p><sup>17</sup>&nbsp;Williamson hasn’t written about the imprecision in degrees of belief so I don’t know if his general solution is intended to apply here.</p></li></div><p>It might be thought that by considering our dispositions to accept or reject bets at certain odds we could settle precisely our credence in a given proposition. Apart from the general objections in earlier chapters there is a particular problem here. Assuming we do have dispositions to accept or reject any bet is quite implausible. For some bets we simply don’t have dispositions about what to do when faced with them. We might, on reflection, choose to accept (or reject) them, but this reflection may involve changing our epistemic state. This means that even if an agent does accept a bet after being offered it, she needn’t have originally had a disposition to accept that bet. Any defence of the claim that all degrees of belief (or even all reasonable degrees of belief) are precise will turn out to rely on an implausible claim somewhere, so this direct argument for allowing imprecision seems to be quite strong.</p>
</section>
</section>
<section id="the-reasonableness-of-precision" class="level2 page-columns page-full" data-number="5.9">
<h2 data-number="5.9" class="anchored" data-anchor-id="the-reasonableness-of-precision"><span class="header-section-number">5.9</span> 5.9 The Reasonableness of Precision</h2>
<p>I have made two assumptions above which might be considered controversial. The first is that it is always reasonable for an agent to believe any proposition to a precise degree. The second is that the union of all reasonable probability functions represents a reasonable epistemic state. The purpose of this section is to defend these assumptions. For simplicity in this section I’ll use the phrase ‘epistemic state’ to refer to a set of probability functions representing an epistemic state.</p>
<p>I’ll start with the defence of the second assumption. I don’t want to defend the claim that whenever C&nbsp;<sub>1</sub> and C&nbsp;<sub>2</sub> are reasonable states then C&nbsp;<sub>1</sub>&nbsp;∪&nbsp;C&nbsp;<sub>2</sub> is a reasonable state. I think reasonable states must satisfy some kind of continuity principle, so that the agent’s degree of belief in a proposition must be an interval. I do, however, want to defend the related claim that whenever C&nbsp;<sub>1</sub> and C&nbsp;<sub>2</sub> are reasonable states then some superset of C&nbsp;<sub>1</sub>&nbsp;∪&nbsp;C&nbsp;<sub>2</sub> is a reasonable state. This just amounts to the claim that whenever two reasonable agents disagree on the probability of some proposition, there is a reasonable state which is neutral on the question of which of them is right. That seems plausible enough; if all participants in a debate are being perfectly reasonable, there is no requirement on a reasonable agent that they make a decision between the participants. From this principle it follows straightforwardly that some superset of the union of reasonable epistemic states is a reasonable epistemic state.</p>
<p>The first assumption is a little harder to defend. Some writers have thought that the arguments of the last section show more than I’ve intended. They show that under some circumstances, particularly when there is little evidence about a proposition, it is unreasonable to believe that proposition to a precise degree. This, for example, seems to be the view Keynes takes. On any evidence set there is only one reasonable epistemic state, and subsets of that state are not reasonable. The position adopted here is that all subsets of reasonable epistemic states are reasonable.</p>
<p>The first argument for this relies on conclusions not yet justified. In subsequent chapters I will be arguing for a decision theory called Caprice. According to this theory, a set of choices and dispositions to choose is reasonable iff the agent is reasonable and there is a probability function <em>Pi</em> in the agent’s epistemic state such that, for every choice of (or disposition to choose) <em>A</em> over <em>B</em>, the expected value of <em>A</em> according to <em>Pi</em> is at least as great as that of <em>B</em> according to <em>Pi</em>. There are no restrictions on how an agent chooses <em>Pi</em> from her epistemic state<a href="#fn18" class="footnote-ref" id="fnref18" role="doc-noteref"><sup>18</sup></a>. So an agent whose epistemic state is C , where <em>Pi</em>&nbsp;∈&nbsp;C , will make exactly the same decisions as an agent whose epistemic state is {<em>Pi</em>}. If this decision theory is right, it follows that precisifying (i.e.&nbsp;an agent moving from epistemic state C to epistemic state C&nbsp;<sub>1</sub>, a subset of&nbsp;C&nbsp;) can never lead to the agent making decisions which would have been irrational according to the coarser epistemic state. So from a purely pragmatic perspective, there is no cost to precisifying, hence it is not irrational.</p>
<div class="no-row-height column-margin column-container"><li id="fn18"><p><sup>18</sup>&nbsp;This language of choosing <em>Pi</em> is perhaps a bit misleading. The picture I have in mind is that the agent simply makes choices and if she is reasonable the condition will sort itself out. There is no conscious decision to choose according to a particular probability function.</p></li></div><p>There is more to being reasonable than not losing money, so I’m sceptical about the force of this argument. A stronger argument turns on the possibility of rational disagreement. Assume epistemic state C is the largest reasonable state. There are three possibilities: all subsets of C are reasonable; some but not all subsets of C are reasonable, and finally that no subsets of C are reasonable. We are wanting to show the first is correct, so assume for now it is false. The second seems implausibly arbitrary; what ground could there be for distinguishing the reasonable precisifying moves from the unreasonable ones? And the third does not allow reasonable agents to disagree, it requires all reasonable agents to have the same (imprecise) degree of belief in a proposition on a given evidence set. This is the position Keynes adopted, but it is refuted by the possibility of reasonable disagreement. So the first option, which is what I wanted to defend, is the only one left standing.</p>


</section>


</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const disableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'prefetch';
    }
  }
  const enableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'stylesheet';
    }
  }
  const manageTransitions = (selector, allowTransitions) => {
    const els = window.document.querySelectorAll(selector);
    for (let i=0; i < els.length; i++) {
      const el = els[i];
      if (allowTransitions) {
        el.classList.remove('notransition');
      } else {
        el.classList.add('notransition');
      }
    }
  }
  const toggleGiscusIfUsed = (isAlternate, darkModeDefault) => {
    const baseTheme = document.querySelector('#giscus-base-theme')?.value ?? 'light';
    const alternateTheme = document.querySelector('#giscus-alt-theme')?.value ?? 'dark';
    let newTheme = '';
    if(darkModeDefault) {
      newTheme = isAlternate ? baseTheme : alternateTheme;
    } else {
      newTheme = isAlternate ? alternateTheme : baseTheme;
    }
    const changeGiscusTheme = () => {
      // From: https://github.com/giscus/giscus/issues/336
      const sendMessage = (message) => {
        const iframe = document.querySelector('iframe.giscus-frame');
        if (!iframe) return;
        iframe.contentWindow.postMessage({ giscus: message }, 'https://giscus.app');
      }
      sendMessage({
        setConfig: {
          theme: newTheme
        }
      });
    }
    const isGiscussLoaded = window.document.querySelector('iframe.giscus-frame') !== null;
    if (isGiscussLoaded) {
      changeGiscusTheme();
    }
  }
  const toggleColorMode = (alternate) => {
    // Switch the stylesheets
    const alternateStylesheets = window.document.querySelectorAll('link.quarto-color-scheme.quarto-color-alternate');
    manageTransitions('#quarto-margin-sidebar .nav-link', false);
    if (alternate) {
      enableStylesheet(alternateStylesheets);
      for (const sheetNode of alternateStylesheets) {
        if (sheetNode.id === "quarto-bootstrap") {
          toggleBodyColorMode(sheetNode);
        }
      }
    } else {
      disableStylesheet(alternateStylesheets);
      toggleBodyColorPrimary();
    }
    manageTransitions('#quarto-margin-sidebar .nav-link', true);
    // Switch the toggles
    const toggles = window.document.querySelectorAll('.quarto-color-scheme-toggle');
    for (let i=0; i < toggles.length; i++) {
      const toggle = toggles[i];
      if (toggle) {
        if (alternate) {
          toggle.classList.add("alternate");     
        } else {
          toggle.classList.remove("alternate");
        }
      }
    }
    // Hack to workaround the fact that safari doesn't
    // properly recolor the scrollbar when toggling (#1455)
    if (navigator.userAgent.indexOf('Safari') > 0 && navigator.userAgent.indexOf('Chrome') == -1) {
      manageTransitions("body", false);
      window.scrollTo(0, 1);
      setTimeout(() => {
        window.scrollTo(0, 0);
        manageTransitions("body", true);
      }, 40);  
    }
  }
  const isFileUrl = () => { 
    return window.location.protocol === 'file:';
  }
  const hasAlternateSentinel = () => {  
    let styleSentinel = getColorSchemeSentinel();
    if (styleSentinel !== null) {
      return styleSentinel === "alternate";
    } else {
      return false;
    }
  }
  const setStyleSentinel = (alternate) => {
    const value = alternate ? "alternate" : "default";
    if (!isFileUrl()) {
      window.localStorage.setItem("quarto-color-scheme", value);
    } else {
      localAlternateSentinel = value;
    }
  }
  const getColorSchemeSentinel = () => {
    if (!isFileUrl()) {
      const storageValue = window.localStorage.getItem("quarto-color-scheme");
      return storageValue != null ? storageValue : localAlternateSentinel;
    } else {
      return localAlternateSentinel;
    }
  }
  const darkModeDefault = false;
  let localAlternateSentinel = darkModeDefault ? 'alternate' : 'default';
  // Dark / light mode switch
  window.quartoToggleColorScheme = () => {
    // Read the current dark / light value 
    let toAlternate = !hasAlternateSentinel();
    toggleColorMode(toAlternate);
    setStyleSentinel(toAlternate);
    toggleGiscusIfUsed(toAlternate, darkModeDefault);
  };
  // Ensure there is a toggle, if there isn't float one in the top right
  if (window.document.querySelector('.quarto-color-scheme-toggle') === null) {
    const a = window.document.createElement('a');
    a.classList.add('top-right');
    a.classList.add('quarto-color-scheme-toggle');
    a.href = "";
    a.onclick = function() { try { window.quartoToggleColorScheme(); } catch {} return false; };
    const i = window.document.createElement("i");
    i.classList.add('bi');
    a.appendChild(i);
    window.document.body.appendChild(a);
  }
  // Switch to dark mode if need be
  if (hasAlternateSentinel()) {
    toggleColorMode(true);
  } else {
    toggleColorMode(false);
  }
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    const typesetMath = (el) => {
      if (window.MathJax) {
        // MathJax Typeset
        window.MathJax.typeset([el]);
      } else if (window.katex) {
        // KaTeX Render
        var mathElements = el.getElementsByClassName("math");
        var macros = [];
        for (var i = 0; i < mathElements.length; i++) {
          var texText = mathElements[i].firstChild;
          if (mathElements[i].tagName == "SPAN") {
            window.katex.render(texText.data, mathElements[i], {
              displayMode: mathElements[i].classList.contains('display'),
              throwOnError: false,
              macros: macros,
              fleqn: false
            });
          }
        }
      }
    }
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        typesetMath(container);
        return container.innerHTML
      } else {
        typesetMath(note);
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      typesetMath(note);
      return note.innerHTML;
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./chap-04.html" class="pagination-link  aria-label=" &lt;span="" probability="" is&lt;="" span&gt;"="">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">What Probability Is</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./chap-06.html" class="pagination-link" aria-label="<span class='chapter-number'>6</span>&nbsp; <span class='chapter-title'>Objections</span>">
        <span class="nav-page-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Objections</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->




</body></html>