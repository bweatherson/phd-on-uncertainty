# What Probability Is {#sec-chap-4}

## 4.1 The Probability Relation {#the-probability-relation}

If probability is to be analysed as reasonable degree of belief, then it must be relational. I have simply assumed this in previous chapters, but there is a rather simple reason for it. What is reasonable to believe depends on what the evidence is. It was reasonable to believe in 1991 that George Bush would win the 1991 Presidential election, but not in 1993 to believe that he did. In probabilistic language, the reasonable degree of belief in *George Bush wins the 1992 Presidential election* for anyone in 1991 was rather high. However, by 1993 the reasonable degree of belief in it became quite low. So consistency demands that probability sentences are also relational in some way. They don't necessarily have to refer directly to the hypothesis whose probability is in question and the evidence. The evidence can be, and often is, referred to by rather circuitous paths. First, it is more common to refer to a rule for determining the evidence than the evidence itself. Secondly, that reference is itself often implicit and determined by context. But a reference to evidence will always be there, as both Keynes and Carnap were careful to point out.

> The fact that *probability*~1~ \[=probability\] *is relative to given evidence* and that therefore a complete statement of probability~1~ must contain a reference to the evidence is very important. Keynes was the first to emphasise this relativity. The omission of any reference to evidence is often harmless if the elliptical nature of the statement was clearly recognised. However, this omission was the general custom with earlier authors, and it often caused lack of clarity (Carnap 1950: 31, italics in original).

Carnap thought he needed to distinguish two types of probability, one of which he refers to in this quote as probability~1~. This is part of the evidence that probability sentences do contain hidden references to evidence. Carnap thought that the term 'probability' was systematically ambiguous, and generations of theorists have agreed with him. If probability sentences are read as absolute this ambiguity becomes inexplicable, as indeed Carnap thought it was. However, once it is noted that they contain hidden references apparent ambiguity can be explained away as changes in hidden references. But to see this some background is needed.

### 4.1.1 The Relata Are Propositions

If probability is a relation, what are the relata? Carnap held that they were sentences. I think it better to take the relata to be propositions. There are two reasons for this; basically the two objections that I made to the syntactic nature of Carnap's theory in section 1.7. The first, which I won't recount, is that syntax seems little guide to probability in cases where we have doubts about the projectability of the predicates being used. The second, which I said very little about there, is that often we can't put our evidence in sentential form.

If we take evidence to be sentential, we have to buy into arguments about the theory-dependence of language and about whether or not we can construct an observation language. In particular, it seems that we might be committing ourselves to being on the losing side of these arguments. So I borrow a technique from Lewis (1996) in order to construct a unique proposition from our sense data. Propositions are simply sets of possible worlds. Proposition *p* is just the set of worlds in which *p*. For any possible world *w*, let *w* be in *p* iff *w* is consistent with all our sense data, over our history. We might for some purposes want *p* to include all worlds which are consistent with our current internal states. This would allow us to, for example, give a non-zero probability to the proposition that the world was created two seconds ago with all our memories hard-wired into us. However, I'll assume that Lewis's definition of evidence is generally correct, and that our sensations of yesterday are part of our evidence. Now *p* is clearly a proposition, though it may not be clear which proposition it is. This may be due to some vagueness about what qualifies as sense data. I am thinking here particularly of phenomena such as blind-sight which might make us think that it is a vague matter whether a given world is consistent with a subject's sense data or not. But I have avoided the problem of there being no sentence in any particular language which accurately captures all and only our evidence. That such an evidence sentence can't be given counts against taking the relata to be sentences; that I can give an evidence proposition counts for taking the relata to be propositions.

### 4.1.2 Chance

Given this definition of probability in terms of a relation between two propositions, we can define some related notions, such as objective chance. Various 'events', such as the decay of an atom, are often held to have an objective chance of happening. Even given all the initial conditions we could not in principle say whether or not the atom will decay, just what its chance of decay is. Carnap thought that this required a different probabilistic concept, which he christened probability~2~, ^­^­and analysed in terms of frequencies. Following Lewis (1980), I call the concept 'chance' and claim that it should be understood in terms of propensities, not frequencies. However, unlike Lewis, I think chance can be analysed purely in terms of probability itself, or degrees of reasonable belief. The point of this subsection is to note what this analysis is, and to deal with a technical issue concerning the tensed nature of chance sentences. Defence of the analysis is delayed until section 4.3.

The fundamental fact known about chance is what Lewis calls the Principal Principle (PP). I have implicitly assumed this in previous chapters. The PP says that, if an agent knows that the chance of *p* at some time is *x* and has no other 'admissible' information, then the only reasonable degree of belief they can have in *p* is *x*. Admissible information is, in Lewis's terms, "information whose impact on credence about outcomes comes entirely by way of credence about the chances of those outcomes." (Lewis 1980: 92) What is admissible is time-dependent. That the suspect fired the gun at midday is admissible information at midday, but not at 11am. For my purposes, 'purely historical' information is always admissible at *t*. So, at *t*, if an agent knows the chance of *p* is *x* and knows nothing that is strictly about the future, they have no working crystal balls or such devices, then the only reasonable degree of belief in *p* is *x*.

Lewis notes one possible analysis of chance that could be derived from the PP, but for reasons we'll look at in later sections denies that it works. The analysis is derived from how we cash out 'purely historical' information. As is well known, it is very hard to cash out the intuitive notion of the time that a sentence is about from purely syntactic features of the sentence, such as what times are mentioned. Again, a move to propositions saves the day. A proposition is purely historical iff it is true in all possible worlds which are an exact match for this world to the present time. The history of the world proposition for the present is the conjunction of all such propositions. More generally, the history of the world proposition for world *w* at *t* is the set of all possible worlds which are an exact match for *w* to time *t*. Call this proposition *H~w~*~, *t*~. So as a first approximation, the chance of *p* at *t* in *w* is the probability of *p* given *H~w~*~, *t*~.

In simpler terms, chance is probability (i.e. reasonable degree of belief) given total history. However, while that is a good enough analysis for 'The chance of *p* at *t* is such-and-such', for the apparently simpler sentence 'The chance of *p* is such-and-such', we need a more complicated analysis. The following approach might be plausible. If the time is now *t*, the proposition *The chance of p is r* is the set of worlds *w* such that the probability of *p* given the history of *w* to *t* is *r*. The problem with this approach is that it makes knowing what time it is a prerequisite for knowing the chance of *p*. Let *w*~1~ be a possible world such that the probability of *p* given the history of *w*~1~ to *t*~1~, which is some time other than *t*, is *r*, but which is also such that the probability of *p* given the history of *w*~1~ to *t* is not *r*. Then, on this hypothesis, an agent who knows that the chance of *p* is *r* will know that *w*~1~ is not the actual world. This seems a bit strong. An agent who doesn't know whether the time is *t* or *t*~1~ will presumably not have enough information to know she is not in *w*~1~.

So we have to complicate the analysis of chance sentences by using a device also due to Lewis, in this case to his (1979b). *The chance of p is r* is a proposition *de nunc*. Put relatively formally, we can say that the possibility space of which this proposition is a subset is not the set of possible worlds but rather the set of tensed possible worlds. A tensed possible world is just a pair of a world and a time. The time can be thought of as 'the time it is' in that tensed possible world. Now when an agent knows what time it is, this knowledge doesn't allow them to say that certain possible worlds are not actual (except perhaps some short-lived worlds). Rather, it allows them to rule out all tensed possible worlds except those where the time is what it actually is. Knowing *The chance of p is r* allows an agent to rule out all tensed possible worlds \<*w*´, *t*´\> except those where the probability of *p* given the history of *w*´ to *t*´ is *r*. In our above example, the agent couldn't rule out the possibility that the actual *tensed* possible world was \<*w*~1~, *t*~1~\>, and hence couldn't rule out that *w*~1~ was the actual world, as required.

## 4.2 Necessitarian Probability {#necessitarian-probability}

I find internalism about justification highly plausible. It would be odd indeed if what was reasonable for me to believe was unreasonable for a brain in a vat with my sense data, or if what was reasonable for the vat-ensconced brain was unreasonable for me. Obviously, what I know and what the brain knows could be different; the requirement that what is known is true entails that. But the moral of the considerations about what would be reasonable is, I think, that what it is reasonable to believe, what degrees of belief are reasonable in a proposition, is determined entirely by internally available data. Knowing someone's evidence determines entirely what it is and isn't reasonable for them to believe.

There is a larger debate about internalism which I could buy into. But that would be a different dissertation. Rather, I'll let the brain-in-vat considerations flagged in the previous paragraph be enough grounds to take internalism more or less for granted. Now, if we're internalists, we get a curious result. Internalism says that what it is reasonable to believe supervenes on evidence. This is a *modal* or interworld supervenience claim. If it is reasonable in world *w* to believe *p* to degree *d* on evidence *e*, then it must be that it is reasonable in *w*^\*^ to believe *p* to degree *d* on evidence *e*. No variation in reasonable degree of belief without variation in evidence. So, continuing our example, that a person's entire evidence is *e* entails that it is reasonable for them to believe *p* to degree *d*. And the converse claims also carry through. Had it been unreasonable in *w* to believe *p* to degree *d* on evidence *e*, that would have meant that a person's entire evidence being *e* entails that it is unreasonable for that person to believe *p* to degree *d*.

To put the same points more dramatically, probability statements are, in their complete form, necessary[^49]. If the probability of *p* given *q* is less than 0.5, then it must be less than 0.5. This might seem like a refutation of our theory. Surely, the objection goes, statements like 'The Yankees will probably win the next World Series' are empirical. Call this sentence *S*. *S* is false in the actual world, but we could imagine worlds in which it is true (or conversely if you like the Yankees' chances). The objection misses an important point. Sentences like *S* are, as Carnap noted, elliptical. *S* says that the probability of the Yankees winning the next World Series is more than 0.5, *relative to some contextually determined evidence*. I think the most natural is the history proposition of the world to the present, but it might be something else. I'll look at this question in more detail in the next section. Now it is an empirical matter which proposition that is, and with different histories substituted for the elliptical evidence we might get different truth values. But the full sentence, with the elliptical clauses cashed out the way they actually are, *S* becomes necessary.

[^49]: Might they even be analytic? Probably not. I argue in section 4.4, that according to a plausible kind of relativism about what is reasonable, probability sentences are necessary *a posteriori*. Even if probability sentences are *a priori*, it requires a rather liberal definition of 'analytic' to count these as analytic.

Many people think that probability could not be a necessary relation (i.e. that probability sentences are either necessarily true or necessarily false), so it is instructive to see how little I have used to get this far. The premises are just three.

1.  Probability should be analysed as reasonable degree of belief

2.  Internalism about reasonable belief: what it is reasonable to believe supervenes on evidence

3.  Whenever all *A*-worlds are *B*-worlds, *A* entails *B*.

Anyone who wants to challenge the notion of necessary probability has to challenge one of these premises or the inference from these to the theory that probability is a necessary relation. And I hope the above has convinced the reader that this would be a non-trivial exercise. None of this should be taken as a recantation of my opposition to logical analyses of probability as in Carnap. We can, and do, say that some degrees of belief are unreasonable given certain evidence without saying there is a distinctive syntactic relation between the hypothesis and the evidence for it. Just because this relation holds in all possible worlds if it holds at all, we aren't required to assume it holds by virtue of syntax.

## 4.3 Ambiguity and Relations {#ambiguity-and-relations}

There is one obvious objection to the theory outlined here. I have said that probability is essentially relational. However, probability sentences seem 'absolute' in some sense. We can say, sensibly, that it is probable that Oswald killed JFK, or that the Yankees will win the next World Series. Here is seems probability is being applied to single propositions, not pairs of propositions. This objection crops up recurrently in the literature, the most recent manifestation being Lowe (1996). He thinks the only way of getting around the problem is to understand these absolute probabilities as probability conditional on a tautology.

If that were the only available move the theory would be in difficulty. However, there are better moves available. I hold that in all cases where no evidence is explicitly mentioned (and indeed in many where it is) there is an implicit reference to evidence. We can regard the sentence as elliptical for a sentence in which the reference to all the evidence is explicit. To make this move we don't need any particularly extravagant linguistic tools. Which evidence is being referred to will usually be determined by what Lewis calls 'conversational score', Quinean principles of charity, and perhaps some general conventions. I'll make some speculations as to the nature of these conventions below. It would be nice to know precisely what the conventions are, but for the defence against this objection I only need the plausible hypothesis that there are such conventions.

To note that the tools I am using are not 'extravagant', we can see that they are needed to explain quantifiers in ordinary language. If we took the domain of any quantifier to be as large as possible, then anyone saying "All glasses are empty" would speak falsely. After all there are always some glasses somewhere in the universe which are not empty. However, this can sometimes be said truly, and the best explanation of that is that the domain of 'all' is implicitly restricted to nearby things, or to things under consideration. Generally the scope of quantifiers, the set of things 'under consideration' will be determined by conversational score. However, sometimes that set will expand because of new items which are drawn to the attention of speakers. Now we can either deal with this by developing more complicated rules for conversational scorekeeping, which is what Lewis does, or we can have a less restrictive context and be more reliant on charity considerations. Either way, whatever tools we need to explain quantifiers will be sufficient to explain the elliptical references that I need, which eliminates, I hope, one potential implausibility.

We can turn this defence against Lowe's objection into an advantage of the theory. Since Carnap (1945), many writers have held that 'probability' is ambiguous, referring sometimes to an epistemic concept (either objective, as here, or subjective, as in some other writers) and sometimes to objective chance. I can explain the data they rely on by means of the elliptical nature of probability sentences. In the next sub‑section I argue that reducing a brute ambiguity, as in Carnap, to a mere ellipticality is a theoretical advantage. In the following sub‑section I argue that the ellipticality theory does better than the ambiguity theory at explaining three general features of our usage of probability. Finally I make some speculations about the conventions governing implicit references to evidence.

### 4.3.1 Ambiguity and Ellipticality

I need to make clearly my distinction between ambiguous and elliptical terms. The difference is best brought out by examples. *Bank* is clearly ambiguous in that it might refer either to a financial institution or a riverside. On the other hand, a term like *citizen* is what I'll call elliptical. In various contexts, uttering *Lisa is a citizen* might mean that she's a citizen of Australia, or Britain, or France, or wherever. Which of these is referred to will depend on the conversational score. We can always specify which proposition we were referring to by being explicit about what *citizen* meant, eg by uttering *Lisa is a French citizen*. So, like *bank*, *citizen* can refer to different things on different occasions. However, unlike *bank*, all the possible referents of *citizen* are closely related, they have a large common meaning. Indeed, for some purposes we might say that this common meaning is the meaning of *citizen*. It is clear that there is no particular relation between financial institutions and river sides that grounds their being referred to by the same word. They are not, in the phrase I have used above, different facets of the same concept. So while both *bank* and *citizen* are ambiguous in a weak sense, they both can mean different things in different contexts, in a stronger sense *bank* is ambiguous and *citizen* is merely elliptical.

There are many important terms in philosophy which are elliptical. Definite descriptions like *the dog* will generally be elliptical. Focus on definite descriptions like *the King of France* can make us forget that most of the times we use a definite description we don't assume there is at most one possible referent, but merely a unique contextually relevant referent. Modal terms like *possible* are elliptical; indeed I suspect the ellipticity of *possible* and *probable* is linked. More contentiously, I suspect that conditionals are elliptical; this would explain the strong connections between different types of conditional (eg indicative and subjunctive) without denying that in a weak sense the conditional form can take different meanings. Even our simplest connective *and* is, I think, elliptical. In one sense it carries Gricean implicatures, and in another it doesn't[^50]. But I'm getting away from my main topic.

[^50]: To see what I was getting at, compare the following two utterances.

    Clark Kent went into the phone booth and Superman came out.

    In the weekend football results, Essendon beat Sydney and Brisbane beat Carlton.

    The first carries an implication of temporal ordering, but to my mind at least the second does not. It isn't that the implication is cancelled in the second case, it just wasn't there to begin with. If that's right we have to consider the tricky question of what makes maxims applicable.

    Even if I'm wrong here, 'and' might be elliptical in another sense. Generally 'and' carries an implication of order. But whether this is temporal order, or order of importance, or some other order will be determined by the context. Given the way I've set up elliptical terms, this is enough to make it elliptical.

    The first example above is used by Saul (1997) to make a somewhat different point about implicature.

Why is reducing an ambiguity to an ellipticality an advantage? There are two closely related reasons. The first is a simple appeal to Occam's Razor. If probability is elliptical there is only one distinct 'thing' we have to appeal to in explaining its usage, i.e. its meaning. If it is ambiguous we have to appeal to each of its different meanings. The fewer abstract theoretical entities the better, so the elliptical theory wins. But Occam's Razor is perhaps dubious, particularly when used to argue for quantitative parsimony, not qualitative parsimony.[^51] Since I am not disposing of meanings generally, just reducing the number of them needed, perhaps the appeal is misplaced.

[^51]: Though Nolan (1997) has argued that quantitative, and not just qualitative, parsimony is a theoretical desideratum.

The second is that the ambiguity theorist has, as I'll stress below, some explaining to do. If the different meanings of *probability* are so distinct, why does English use the same word for them? Indeed, why is this replicated throughout other natural languages? We have invented technical terms like *chance* and *credence* for the different meanings, and if the natural language usage of these terms was enough like their technical usage, perhaps the ambiguity theorist would have the start of an explanation. However, this is clearly not the case; 'credible' is undeniably epistemic, but we can use 'chance' in ordinary English to refer to epistemic probability, not what are called in theory objective chances. As I'll show in the next sub‑section, when the ambiguity theorist tries to make this explanation by using new principles, like the PP, the explanatory burden simply moves, so they have to find a plausible explanation for that principle.

What is the sense in which elliptical terms have a single meaning? As noted above, we can say that meaning is the common part between the possible referents. Alternatively, we can say that the meaning for elliptical terms is, like the meaning of indexical terms, just the rule for generating a referent from the context. It is in this sense that I want to say that *probability* has just one meaning, that the probability of *p* given *q* is the reasonable degree of belief in *p* given *q*. More generally, the probability of *p* is the reasonable degree of belief in *p* on evidence *q* for some contextually specified evidence *q*.

### 4.3.2 Problems for the Ambiguity Thesis

I claimed above that chance could be reduced to probability given total history. I don't have a knock-down argument for this reduction. But it seems superior to the competition. In particular it seems superior to the ambiguity thesis: the claim that there are such concepts as epistemic and aleatory probability, and these are ontologically unrelated. As is standard, from now on I'll refer to these concepts as chance and credence. The credence of *p* for an agent is, on my theory, the probability of *p* given the agent's evidence proposition. The ambiguity thesis is rarely defended, but it is often assumed[^52], which makes it harder to argue against. Such a thesis can't, I hold, explain the following three facts:

[^52]: People who endorse it include Carnap (1945), Russell (1948), Hacking (1975), Shafer (1976) and Gillies (1991). Gillies believes it is a consequence of taking *probability* to mean whatever it would be most scientifically useful to mean. The influence of Hacking's argument that aleatory and epistemic probability are clearly distinct concepts seems quite widespread in the social sciences.

-   The one word *probability* is used to refer to both chance and credence.

-   Chance and credence have the same calculus.

-   Knowledge of chances constrains credences.

Because of the reduction of chance and credence to the single concept I can explain each of these. Ambiguity theorists can, I suspect, explain none of them. Hence there is a strong inference to the best explanation in favour of my position. The rest of this sub-section is devoted to setting out more precisely what each of these three explicanda are, why my approach can explain them and why ambiguity theorists cannot.

The first is in effect already discussed. I only bring it up to note the general rule that the burden of proof falls on those wanting to establish an ambiguity. It could be argued here that it was just ignorance on the part of the populace which has led to this confusion between two concepts being named with the one word. Alternatively an historical explanation might shed light on why these two concepts came to share a name. In this context Hacking's book on the history of probability (1975) might be important. As many ambiguity theorists credit the aleatory / epistemic, or chance / credence, distinction to this book, perhaps something like this is in mind. My explanation for the apparent ambiguity is that I argue *probability* is elliptical, as above. When the elliptical evidence is the agent's evidence proposition *probability* has an epistemic meaning, when it is the history of the world proposition, *probability* has an aleatory meaning.

The second refers to the fact that for most theorists, both chance and credence obey the classical probability calculus. Some ambiguity theorists have a clear defence here, for they believe that chance and credence follow different rules. For example, Shafer (1976) believes that classical probability logic is appropriate for chances, but not for credence. He argues that the addition principle, that when *A* and *B* are exclusive *Pr*(*A*) + *Pr*(*B*) = *Pr*(*A* ∨ *B*) doesn't hold when 'Pr' is interpreted as credence. So again some ambiguity theorists have an escape. However, those theorists who accept that the calculi for the two are the same have, I think, some explaining to do. That chance and credence should obey the same calculus is explained on my picture by reducing them each to a single concept.

The third refers to the PP, which makes an epistemological link between chance and credence. I can't find a single argument in the literature for why this link should hold on an ambiguity view, even among those who hold onto the ambiguity position and accept the PP. There is an explanation for the PP in Bigelow and Pargetter (1990: 154‑159), but it doesn't appear to account for the fact that chance statements are tensed, so the explanation here will be different. In any case, they take it as a consequence of there being an explanation that the different probabilistic concepts we use are, in my terms, different facets of the same concept.

The explanation on my account of the PP is a bit roundabout, but I hope interesting. There is an epistemological principle going back to Locke saying that we should use all the evidence at our disposal. In the terms of my theory of probability, our degree of belief in *p* should be determined by the probability of *p* given all our evidence rather than some portion of it. I'll call this Locke's Principle. Occasionally, critics of relational analyses of probability such as the one I'm defending say that no explanation of Locke's Principle can be given by holders of that analysis. This criticism can be found in Ayer (1957)[^53]. I will first show how Locke's Principle and my analysis of chance explains the PP, and then show how the analysis of chance can help explain Locke's Principle.

[^53]: A somewhat different, but I think also successful, reply to Ayer is found in Chisholm (1989).

By my analysis of chance, if we know that the chance of *p* is *n*, then we know that if we had all the possible evidence, ie all the evidence available to the present, we ought believe *p* to degree *n*. By Locke's Principle, we ought act on the maximal available evidence set. In other words, it is rationally preferable to have larger evidence sets. The degree of belief which it is rational to entertain on a larger evidence set is preferable to one which is rational to entertain on a smaller evidence set. But when we know the chance we know the degree of belief we would have on the largest possible evidence set, the history of the world to the present. So my analysis of chance and Locke's Principle entail the PP. Hence my analysis can explain the plausibility of the PP. I suspect that an ambiguity theory will have a much harder task making such an explanation.

The analysis of chance also goes some of the way towards making sense of Locke's Principle. When we are considering propositions about the future, e.g. Blue Hands will win the Derby, which we'll call *p*, we have several competing aims. Arguably, it would be ideal to believe the proposition if it's true and disbelieve it if it's false. Ramsey (1926: 194) for example, says this is the ideal of belief. However, in some circumstances this will be irrational. Even if Blue Hands will go on to win the Derby it would be irrational to be overly confident of this before the Derby is run. Part of the reason for this is that being rational is to have rational habits, and a habit which led to overconfidence in Blue Hands's chances will most likely lead to errors elsewhere.

Aiming to have a true belief about who will win the Derby is not our only aim. We also aim to have justified beliefs and to have our degrees of belief match the chances. The latter requirement is a formalisation of the desiderata noted in the previous paragraph that we be neither overconfident nor underconfident about any particular horse. If we have less than full information, the justified degree of belief in *p* on our evidence and the chance of *p* may diverge. However, if we knew everything about the history of the world and we were reasonable in our compilation of that evidence, by definition our degree of belief in *p* would be the chance that *p*. The motivation for Locke's Principle is that as we get more evidence, as our evidence more closely approximates the history of the world proposition, the reasonable degree of belief in *p* will be more likely to be close to the chance that *p*. This last step is something of an assumption, so I can't take it as a demonstration that Locke's Principle is worthwhile. However, it seems a plausible enough assumption to at least motivate Locke's Principle, and respond to those critics who argue that on this analysis of probability there is no motivation for collecting more evidence.

This section has argued for, in effect, a reduction of chance and reasonable credence to a single concept of probability. This entails a rejection of the popular ambiguity theory, although I accept that probability is weakly ambiguous or what I call elliptical. The principle argument against the ambiguity theory is that it is forced to say that certain facts which are easily explained under this analysis are giant coincidences, so it is a long way from being the best explanation.

As mentioned above, the analysis of chance defended here is due to Lewis, though he didn't accept it because it has a consequence which he found unacceptable. In response, I'll present a short argument as to why this consequence oughtn't be thought of as unduly odd. The problem is that we have an intuitive idea that there is, in most cases, a range of permissible credences. But if chance is analysed this way, and chances are numerical, it seems that all reasonable belief functions must converge in many circumstances. In particular, whenever any reasonable belief function is conditionalised on a history proposition the output must be a single function. (That is, the result of conditionalising any reasonable belief function on a history proposition will be the same). Now there is a dilemma; do I give up on chances being numerical, or do I give up the intuition that there are a variety of different reasonable degrees of belief. It is never said that we have to give up the idea that there are several reasonable belief functions. (A reasonable belief function for Lewis takes evidence propositions as inputs and has numerical reasonable degrees of belief as outputs). It's just that these disparate functions must have the same result under conditionalisation.

First, note that to the realist about chances, this will be no substantial problem. Such a person will think the history proposition of the world includes facts about chances, so the agent who knows the complete history of the world will know the chance of all events that have chances. Since we aim to have degrees of belief match chances, at least when nothing better is available, there is no reason why such an agent should have any degree of belief in *p* other than its chance. But the agent was arbitrary, so all such agent's should have the same degree of belief. Lewis is no realist about chances, so this is no good as an *ad hominen*, but it helps frame the debate.

In particular, the qualification in the above, restricting attention to those events that have chances, is important. Anticipating a little the results of @sec-chap-5, it seems plausible that sometimes *p* has no chance, or perhaps more precisely, the chance of *p* is not numerical. It is simply an assumption in Lewis that chances are numerical, and without that assumption he doesn't have the conclusion that any two people who know the history proposition must have the same numerical degree of belief in *p*. Again anticipating a little, I argue that when the probability of *p* given *q* is non-numerical, i.e. is vague over \[*x*, *y*\] where *x* \< *y*, then an agent can reasonably believe *p* to any degree in \[*x*, *y*\].[^54] And when that is allowed, I don't get the really paradoxical results that make Lewis give up this analysis.

[^54]: Or more precisely have a credence in *p* vague over any sub-interval of \[*x*, *y*\].

> On this hypothesis, enough purely historical information would suffice to tell a reasonable believer whether the half-life of radon is 3.825 days or 3.852. What is more: enough purely historical information *about any initial segment of the universe*, however short, would settle the half-life! (1986: 131, italics in original)

It mightn't be immediately obvious why any short period of historical information would settle the half-life. After all, the half-life of an element of radon now depends on the history of the world until the present. However, each of the possible histories had a certain chance of coming about, so we can calculate the chance of a radon element decaying in a given time as the sum across all possible histories of the chance of that history times the chance of radon decaying in that time given that history. Lewis is assuming a rather strong form of additivity here, surely there are at least uncountably many worlds in question, but I'll let that pass. My point is that there is no justification for saying that the chance of each of these histories is numerical. If Lewis doesn't have this, he won't be able to deduce from initial segments the precise half-life of radon.

If that is unpersuasive, there is another more defensive response to Lewis. The intuition he relies on about the reasonableness of divergence of opinion is developed from our practice in everyday life. Now, in everyday life, no one has knowledge of the complete history of the world. Arguably, in such circumstances, some intuitions about epistemic practices in our world are inapplicable. That is, the cost of accepting a theory in conflict with these intuitions is not as high as it would be were the intuitions about matters with which we have greater acquaintance. Even if one doesn't accept my argument above as to why this is so, Lewis's implicit premise that the intuition is applicable is certainly questionable, and hence he has not knocked out the analysis of chance offered.

### 4.3.3 The Elliptical Referents

I have argued so far that there is an elliptical reference to evidence in every probability sentence. I ought to say something about the content of these references in everyday uses of 'probability'. On my theory this will be an empirical question, so the conclusions of this section are necessarily more speculative than the rest of this dissertation. However, I am confident the answers offered here is at least approximately correct.

My claim is that the implicit evidence in "The probability of *p* is *x*" or variants on it, is evidence which is either available to the speaker, or common knowledge, when *p* is about the past or present and the total history of the world when *p* is about the future. There are two rules: future-directed probability sentences are talking about chances and other probability sentences about reasonable credences given publically available evidence. There may be exceptions to these two rules, but in general they are correct.

The original evidence can be determined by looking at the impact of new evidence, particularly new evidence which is conclusive that *p*. If the new evidence, call it *e*, shows the original probability sentence was incorrect, then *e* was in the original evidence. If it shows the original sentence is now redundant or in some way superseded, then *e* was not. Part of the difficulty here is that telling whether the impact of new evidence is to show the old sentence was incorrect or merely redundant is not straightforward, and in particular is heavily theory-laden.

When *p* is about the past, my intuition is that someone can speak truly in ignorance of genuinely new evidence that will come out in the future[^55], but not in ignorance of evidence that is, in the context of utterance, taken to be widely known. For example, I think the jurors in the second O. J. Simpson trial, who in effect said that it was more probable than not that Simpson killed his wife, spoke truly. And I don't think it would show they spoke falsely if new evidence completely exonerating Simpson appeared tomorrow. However, I don't think that someone who says the probability that Simpson killed his wife is extremely low (or for that matter extremely high) would be speaking truly, even if all the evidence they had pointed in that direction. One can't make *p* improbable by deliberately avoiding all evidence pointing to *p*. Evidence available to the speaker is included in the implicit evidence in order to prevent it ever being proper to say "*p* but it is improbable that *p*".

[^55]: And not just by accident.

It is clear from the Simpson case that the relevant evidence cannot be the history of the world. If that were so it would be false to say "The probability that Simpson killed his wife is between *x* and *y*" unless *x* = 0 or *y* = 1. My intuition is that there are true sentences of that form. So probability sentences about past events are not chance sentences. However, it seems that for future directed sentences the situation is somewhat different. Someone who says "It is probable that Blue Poles will win the 4.15" in between the time that Blue Poles's trainer has decided to remove him from the race and the time this is publically announced to my mind speaks falsely. What they say is reasonable, but wrong. And a similar intuition carries across to all other future-directed probability sentences. In the earlier case we couldn't include all the evidence available in theory, the history of the world, because that would make all probabilities equal 0 or 1. Here that problem is not present, so there is nothing to challenge the intuition that the truth of probability sentences, whatever their reasonableness, should be determined by the widest possible evidence set.

## 4.4 Isms {#isms}

### 4.4.1 Absolutism, Relationism, Relativism and Objective and Subjective

All through the preceding material the questions of what makes a credence reasonable, and how we know one is reasonable, have been left open. As I showed in @sec-chap-3, sets of precise credences which do not conform to the probability calculus are not reasonable. So, anticipating slightly the results of the next chapter, credence distributions should be evaluated for reasonableness rather than single credences. So the questions become: where do the reasonable distributions come from, and how do we know that they are? To answer these we shall look at the question of whether, and to what extent, the set of reasonable distributions can change over possible worlds. I will consider primarily the question of whether the reasonable distributions are determined by social convention, or whether they are fixed by universal principles. That is, I will be looking to see what extent my theory should be relativist or conventionalist.

First, I'll define the terms mentioned in the title of this sub-section. Necessitarian theories are occasionally called subjectivist or even relativist simply because what is reasonable is relative to evidence[^56]. If one wants to distinguish the necessitarian approach from one where probability is a physical magnitude, as in Popper's propensity account, this might be useful, but overall it is not a useful notation, for reasons stressed in section 1.8. In part it rests on a misconception that the probability of *p* is a function of one's evidence. This is not the case. The probability of *p* given *q* can differ from the probability of *p* given *r*, and if we are speaking loosely, not referring explicitly to our evidence when talking about the probability of *p* given some evidence, it might seem that if our evidence is different the probability of *p* is different. But the probability of *p* given *q* is independent of whether or not *q* is our evidence. For clarity, and because terms like 'relativist' and 'subjectivist' have useful meanings, I'll refer to the position that probability must be conditional as relationism. If I add to this the position, implicit in what's above, that the set of reasonable distributions is the same in all possible situations, I'll call the position absolutism. Relationism is consistent with all the other positions I'll discuss; indeed, they all imply relationism.

[^56]: For example in Popper's (1933) he refers to Keynes's theory as a subjectivist theory of probability.

Relativism and conventionalism both say that the set of reasonable distributions is determined in some way by social conventions. Conventionalism says that it is entirely a matter of conventions what is reasonable. These conventions are mostly implicit, and in part may be determined by entrenchment rules in the way Goodman says. Part of the reason that we can infer that probably all emeralds are green from the evidence we have is because *emeralds* and *green* are well entrenched. And entrenchment rules determine conventions of reasonableness. Relativism is like conventionalism in saying that the set of reasonable measures is determined entirely by social conventions, such as entrenchment rules. However, according to relativism, the conventions rigidly determine the set of reasonable distributions. So on a relativist approach, had the conventions been different this wouldn't have affected the probability relation between any two propositions. Because relativism uses rigid designation, if we adopt this theory then there will be some contingent *a priori* truths. In particular, it will be true *a priori*, but only contingently, that following social conventions as to what is reasonable, as to what constitute reasonable distributions, is reasonable.

The only difference between relativism and conventionalism is in how they deal with counterfactuals. And I think relativism deals with them somewhat more appropriately. It sounds very implausible to say that what Sally is doing is rational but that it would have been irrational had the conventions been different. It isn't clear that conventionalism is consistent with the internalism I have assumed from the start. If I am being conventionalist then I have to say that the society relative to which conventions are determined is so small that it impossible to have people in different worlds with the same history but different social conventions, else I would have allowed that people with the same histories could have different reasonable degrees of belief.

So the only plausible construal of conventionalism is where the conventions are set in such a way that the agent has evidential access to them. Even if I allow this, the conventionalist is still in some difficulty, for reasons set out in section 1.7. The basic problem is that conventionalism assumes agents have privileged access to what the conventions in their community happen to be. It turns out to be always unreasonable to not believe that the conventions are what they happen to be. But this is just an empirical matter, so agents should be entitled to make reasonable mistakes about this, as about everything else. So the conventionalist position is implausible.

Relativism is untouched by these attacks, and there are some positive arguments for relativism. The main one has already been mentioned. The absolutist is left relying on implausible notions like Moorean intuition to ground reasonable beliefs. She can avoid this by saying evidence about conventions ought to affect our judgements about other matters, but only at the cost of denying some intuitions about what counts as relevant evidence. Alternatively, the absolutist can say that our actual practice of making probability judgements is based on convention, but this is not necessarily optimally rational. Other communities could show us we have been too restrictive or too permissive in constructing the set of reasonable measures. Presented in this way, absolutism absolves itself of the initial implausibility associated with saying that in a strong sense we have latched on to the one true probability logic just through the 'swamp metaphysics' of our language. In conclusion then, I take it that both relativism and absolutism are live possibilities, but conventionalism is not.

Even if we were to adopt relativism, I don't think we should stop describing the analysis as an objective theory of probability. Carnap says his theory is an objective theory because, "if a certain probability~1~ value holds for a certain hypothesis with respect to a certain evidence, then this value is entirely independent of what any person may happen to think" (1950, 43). O'Donnell (1989) in his discussion of Keynes makes a similar point. Now whether this holds on a relativist view depends on what we take him to mean by 'independent'. At its most natural it means that had people thought differently about what is reasonable, this would make no difference to probability values. And that is a claim which the relativist can endorse. I think the most natural thing for the relativist to say is that probability is an objective relation, but which objective relation it is is determined by what conventions are prevalent in the actual world.

### 4.4.2 Contextualism and Belief

In his (1996) Lewis advocates a contextualist account of knowledge. I want to extend that account here to reasonable degrees of belief. On Lewis's picture, an agent knows that *p* in a certain context iff all the contextually relevant possible worlds consistent with the agent's evidence are *p*‑worlds. Probability functions have as their domain a set of subsets of the possible worlds. As Lewis stresses, in practice 'the possible worlds' should not be taken to include all the possible worlds there are, rather just the relevant ones. Propositions all of whose elements are irrelevant will simply not be assigned a probability, or in effect receive probability zero. In this way, context can affect what counts as a reasonable probability function. If the context is such that *p* is not a relevant possibility it might be reasonable to, in effect, assign *p* probability zero, even if this would not be reasonable were the context changed so that *p* were relevant[^57].

[^57]: As stated this is trivially the case when *p* is a proposition which is about the context. It is not intended in this trivial sense, as I'm sure most readers will have understood.

The contextualist turn makes it possible to defend a theory which has come in for some heavy criticism recently. With all this talk about degrees of belief, the reader might be wondering what has become of our familiar absolute concept of belief[^58]. One rather obvious answer is to say that an agent believes *p* just when their degree of belief in *p* is one[^59]. The objection to this from devotees of the betting analysis is to say that we can believe *p* even when we wouldn't be prepared to bet on *p* at any (finite) odds. This objection is run, for example, by Maher (1993) and Kaplan (1996) who both define belief in terms of cognitive utilities[^60]. The problem with this objection is that it equivocates over context. One of the ways that a world can become relevant for Lewis is that we consider the possibility that it is actual. Now when we are deciding whether to bet on *p* at extremely short odds, it seems pertinent to consider what would happen if ¬*p*. Hence at least one ¬*p* world is relevant. If there were no ¬*p* worlds previously relevant then on all reasonable probability distributions the probability of *p* is 1, because probability distributions are normalised measures across relevant worlds, hence the agent's degree of belief in *p* might be 1 until the idea of the bet is raised, at which stage context changes, and perhaps what degrees of belief in *p* are reasonable change. This is related to the possibility of finkish dispositions to bet mentioned earlier that plague crude betting analyses of degrees of belief. In sum, on the contextualist story it is consistent that an agent would believe *p* to degree 1 yet not accept a bet on *p* at very short odds were it to be offered, hence Maher's and Kaplan's first objection fails.

[^58]: And for that matter of 'knowledge', but that's too long a story to enter into here.

[^59]: Although I will use Lewis's work to defend this answer it is not one that to my knowledge Lewis endorses.

[^60]: They each accept the bizarre conclusion that an agent can believe *p* when their degree of belief in *p* is less than 1/2. Given the broadly functionalist methodology driving the betting analysis, I can't see how they can say an epistemic state such that the agent prefers a ¬*p*‑bet to a *p*‑bet could possibly play the functional role of a belief that *p* and hence be a belief that *p*.

That objection was intended to show that believing *p* to degree 1 is not necessary to believe *p*. It has also been argued that it is not sufficient. Let *t* be the length of time until this tritium atom decays. For all *x* ∈ R^+^, *Ch*(*x* = *t*) = 0, so for all *x* an agent who knows the chances involved will believe *t* is not *x*. But this is nonsense: if beliefs must be closed under infinite conjunction this amounts to the belief that the atom will never decay, and even if they need not be closed under infinite conjunction, the particular beliefs seem implausible. Lewis's response[^61] is to say that this argument makes a rounding error. The chance that *x* = *t* is not zero, rather it is a positive infinitesimal. Hence the agent's degree of belief in *x* = *t* should be positive, and hence they need not believe that *t* is not *x*. If we can accept infinitesimal degrees of belief, this will be a perfectly acceptable answer. However, for the reasons mentioned at the end of chapter three, I'm not convinced these are acceptable.

[^61]: In his (1994).

So my conclusion here is somewhat hesitant. If infinitesimal degrees of belief are acceptable then belief just means degree of belief 1. If they are not then an agent believes *p* just in case *p* is true at all points in the possibility space over which the probability functions in their representor are defined. In that case believing *p* to degree 1 will be necessary but not sufficient for belief. The only objection to this makes two controversial steps. The first is to infer a disposition to bet from the agent's degree of belief. The second is inferring a conditional about the agents actions from that disposition. This amounts to assuming the disposition is not finkish. However, we have good reasons for thinking that if the agent has the disposition it will be finkish, so this objection fails.

## 4.5 Lewis's New Principle {#lewiss-new-principle}

The story about chances above relies heavily on the Principal Principle (PP). Recently, however, Lewis has argued that the PP should be modified to take account of what he calls 'undermining'. The PP is replaced with the descriptively entitled 'New Principle' (NP). In this section I will argue that the existence of undermining should be more of a problem for particular views of chance than for the PP, and that there are independent reasons for thinking views of chance that permit undermining are flawed.

To motivate the differences between the principles we need to say a little more about the role of 'admissible' evidence in the PP. Obviously, just knowing that the chance of *p* at some time *t* is *x* doesn't entail that the only reasonable degree of belief in *p* is *x*. After all, if *t* is ten minutes ago, and you now know that *p*, the reasonable degree of belief in *p* is 1, not *x*. So we have to restrict what else can be known before the PP is applicable. Lewis doesn't do this completely, but speculates that two types of evidence are 'admissible'. The first, which I have spent some time on, are history propositions. The second are what Lewis calls 'theories of chance'.

A theory of chance is a set of history to chance conditionals. A history to chance conditional has, as the name implies, a history proposition as antecedent, and a proposition about chances at the end of that history as consequent. They are admissible because their impact on degrees of belief goes entirely via their impact on beliefs about chances. Lewis thinks that history to chance conditionals are nomic. Given this, it is worth recalling the theory of laws that Lewis wants to defend.

Among the true sentences, some are quite simple. For example, "Socrates is wise" is about as simple a sentence as one could get. Some are quite informative, like the conjunction of all the sentences in a history book[^62]. And some manage to do quite well on each of these counts. Those all men know as the laws. That's the spirit of Lewis's theory, but three complications are needed to get it right. First, we assess simplicity and strength (informational content) on a system-by-system basis, not a sentence-by-sentence basis. Secondly, not just any set with a sufficiently high reading on informational content and simplicity will do, only the best such set counts as a law. However, since Lewis thinks in practice the winner of this contest will be so far ahead of the field that debates about how to trade-off simplicity for strength will be moot, this point has little practical importance. Finally, simplicity has to be relative to a language; in a language with no predicate for wisdom "Socrates is wise" will not be at all simple. So we stipulate that we are concerned with the language in which the predicates are the "real" universals.

[^62]: Assuming the book miraculously contains only truths.

These predicates, and the laws which they make up, do quite a deal of work for Lewis. "If you're prepared to agree that theorems of the best system are rightly called laws, presumably you'll also want to say that they underlie causal explanations; that they support counterfactuals; that they are not mere coincidences; that they and their consequences are in some good sense necessary; and that they may be confirmed by their instances." (Lewis 1994: 478‑9)[^63] As I mentioned in the discussion of Carnap in section 1.7, I am rather sceptical that any such set of predicates which is wide enough to support all the ampliative inferences we make (particularly in social sciences) can be narrow enough to avoid licensing inferences which are unsound, but for now I'll let that slide.

[^63]: All references in this section, unless otherwise indicated, are to Lewis (1994).

The difficulty Lewis sees with this picture is that laws, being 'in some good sense necessary' must have no chance of being false. But laws, and hence chance statements, don't supervene on history: the relevant supervenience is on the complete facts about the world past, present and future. This opens up the possibility of undermining. Formally, let *T* be the theory of chance for this world. Since *T* is either a law or the consequence of some laws, the chance of *T* must be 1. As chances don't supervene on history, there may be worlds which have the same history as this one, but in which *T* is not the law.

> Let *F* be some particular one of these alternative futures: one that determined different present chances than the actual future does. *F* will not come about, since it differs from the actual future. But there is some present chance of *F*. That is, there is some present chance that events would go in such a way as to complete a chancemaking pattern that would make the present chances different from what they actually are. The present chances *undermine* themselves (482).

Undermining is certainly peculiar. How it works in practice can be illustrated by taking a simple frequentist account of chance[^64]. There is some positive chance that every tritium atom from now to the end of the universe will decay in under four days, despite tritium having a half-life of 12.26 years. The chance may be infinitesimal, but Lewis allows that. Indeed he invokes enough infinitesimals to revert back to an idea of Keynes's, saying that the chance of an event at *t* is zero iff the laws and facts at *t* rule out that event, and the reasonable degree of belief in *p* is zero iff *p* is inconsistent with the evidence available. Now if this strange pattern of tritium decays were to happen, the chance of a given atom decaying in under four days now would be higher than it actually is, because the frequency of decay inside four days would be massively higher.

[^64]: This illustration is used by Lewis.

This makes undermining look at least possibly inconsistent. Lewis invokes the PP to get a formal inconsistency. Let *E* be any proposition satisfying two conditions. First, it specifies the chance of *F*, the proposition mentioned in Lewis's quote above. Secondly, it contains no inadmissible information about the future; "it does not give any information about how chance events in the present and future will turn out" (483). From the PP we get the equation:

*Pr*(*F* \| *E*) = *Chance*(*F*)

Now take a particular case, let *E* be the whole truth about present chances, and *F* be as above. Since *F* has some chance of coming about *Pr*(*F* \| *E*) \> 0. But *F* and *E* are inconsistent, if *F* is true then chances are different to what they actually are, i.e. *E* is false. So *Pr*(*F* \| *E*) = 0. Contradiction.

As is common, a distinctive feature of a theory of probability can be mirrored in a non-probabilistic theory. Usually this mirroring will be between a writer's probabilistic and absolute epistemology. Here the mirroring is between Lewis's probabilistic and absolute metaphysics. Whether or not *L* is, and always has been, a law is not determined by the present and past 'history of the world', or the Humean facts to the present. So there may be a future, say *G*, such that *L* and all other actual laws are true in *G* but a world with our past and present and *G* as a future does not have *L* as a law. So is *G* possible in the 'good sense' Lewis mentions? Well it is consistent with the laws, so yes. But if *G* were true, the past would be changed, *L* would no longer be a law then as it actually was. And it is impossible in this sense to chance the past[^65], so *G* is impossible. Is this a contradiction? Perhaps not; perhaps there is an equivocation on 'possible' here, as frequently happens in discussions of possibility and time. Still, it seems that laws can undermine themselves just as effectively as chances.

[^65]: As was stressed by Lewis (1976a).

What ought our response be to the possibility of undermining? Lewis responds by qualifying the 'admissibility' criteria in the PP in two ways. The first is to say admissibility admits of degree. Some information may be strictly inadmissible, so knowledge of it waives our obligation to correlate degrees of belief with known chances, however very nearly admissible, so reasonable degrees of belief must still be close to known chances. Secondly, and self-evidently, the admissibility of information may be different for different propositions. *A* may contain much evidence relevant to whether or not *p* which does not impact on beliefs about the chance of *p*, but little information of this kind about *q*. With these tools in place we can say that information about present chances is for almost all propositions almost entirely admissible. This resolves the contradiction that Lewis had uncovered in his earlier position. The propositions *E* and *F* he used were inconsistent, so *E* is completely inadmissible relative to *F*. However, relative to most propositions *E* will be almost entirely admissible.

So the PP cannot be used to generate inconsistent requirements on rational agents. However, Lewis still worries that it can be used to generate incorrect requirements. So we get a slight modification of the PP. Letting *H* be the history proposition to the present, *T* the theory of chance for the world, and *A* any proposition, the old principle said that:

*Chance*(*A*) = *Bel*(*A* \| *HT*).

We were led into difficulties when *A* and *T* were too closely related. The new principle fixes this by conditionalising the left hand side as follows:

*Chance*(*A* \| *T*) = *Bel*(*A* \| *HT*).

This reflects the imperfect admissibility of chance sentences. By such moves, Lewis rescues enough of his view of chance to be satisfied. The more obvious response to undermining is to see it as a problem for Lewis's view of chance. His account makes undermining possible, but it oughtn't be possible, so we ought reject Lewis's view. There are two reasons we might wish to regard undermining as impossible. The first is a related set of intuitions about chance, the second a plausible principle about chance which is incompatible with the existence of undermining.

The intuitions that are incompatible with undermining revolve around the tensed nature of chance statements. At some level, a statement that the chance of *p* at *t* is *x* is 'about' *t*. This could be cashed out in many ways. We might say that whatever happens beyond *t* is irrelevant to the truth of the statement, that it is possible in theory to know whether or not that statement is true at *t*, or that its truth value cannot be changed by events that happen after *t*. Any of these renditions will make it undermining impossible. On Lewis's view of chance, there is no sense in which a chance statement is about *t*. As already noted, it may still be contingent in some good sense[^66] at *t* whether or not the sentence is true, because it might be undetermined whether or not the chance statement will be undermined. So we cannot know that chance statements are true, since to know these requires knowledge of the laws, and knowledge of those requires unattainable knowledge of what will happen in the future.

[^66]: Whether that sense is nomic contingency will turn on definitions of nomic that are at issue here.

We can put the same point in terms of the powers of agents. Tim can't kill his grandfather, because whether or not Grandfather died at a certain time in the past is invariant on whatever subsequently happens in either internal or external time. However, on Lewis's view Tim can affect what the chance was of grandfather dying at a past time. What that chance was is not invariant on what happens in later external time.

The objection here mirrors the objection raised by Peter Menzies to Lewis's analysis of causation. As he does with chance, Lewis analyses causation in 'global' terms. Whether or not *A* causes *B* in a given world depends not just on 'local' facts about *A* and *B* and their immediate environment, but on global facts which determine what the laws are for that world. Lewis needs arguments to defeat the intuitions that private causation and private chances are possible.

The second objection to undermining turns on a principle first enunciated by Bigelow, Collins and Pargetter (1993), something they call the Basic Chance Principle (BCP). The BCP says that if the chance of *p* in world *w* at time *t* is *x*, and *x* \> 0, then there is some world with the same history as *w* to *t* in which *p* is true and the chance of *p* at *t* is *x*. The idea behind it is that in saying the chance of *p* is greater than zero, we are saying *p* is in some sense now possible. That is, we are saying in some world like this one, i.e. in which the history is the same and the chance of *p* is the same, *p* occurs. It follows from the BCP that chances must supervene on history, and hence undermining is impossible. If we're committed enough to theories which insist undermining is possible we may have justification for dismissing the BCP as an excessively onerous burden on theory, which is what Lewis does. I bring it up here to note there is a general reason for insisting on supervenience of chances on history, beyond the intuitions about localness mentioned above.

These two arguments point against views of chance which permit undermining, and in favour of views which make current chances supervene on history to the present. As argued earlier in the chapter, some of Lewis's objections to such a view turn on the unjustified assumption that chances are numerical. Once that assumption is dropped, the analysis of chance as 'objectified credence' I advocated seems to do all the work we could want. And that analysis is compatible with, indeed entails, the old PP, so I have no need to move to the new principle.

